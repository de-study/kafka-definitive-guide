*kafka 스터디에서 책「카프카핵심가이드」 정리한 내용입니다.
> 데이터에서 신뢰하는게 뭘까? 데이터 신뢰성을 보장하기위해 어떻게 설정값을 설정할까? 그 의미는 뭘까?
# Chapter07. 신뢰성보장(Reliable Data Delivery)
<br><br>

# Introduction
### (1)신뢰성의 본질
- 왜 하는가: 신뢰성은 단일 컴포넌트가 아닌 전체 시스템의 속성이라는 걸 먼저 이해해야 함
- 핵심: Kafka만으로는 안되고, 연동되는 모든 시스템이 중요함
- 팀워크: 카프카 관리자, 리눅스 관리자, 네트워크/스토리지 관리자, 개발자 모두가 협력해야 함
>"내가 Meta에서 배운 건 - 장애는 항상 경계선에서 발생한다는 거야. 카프카와 다른 시스템 사이의 연결점을 주의깊게 봐야 해."
### (2) Kafka의 유연성과 위험성 파악
- 왜 하는가: 카프카가 매우 유연하기 때문에 잘못 설정하면 신뢰성을 잃을 수 있음을 알아야 함
- 예시: 웹사이트 클릭 추적 vs 신용카드 결제 - 각각 다른 신뢰성 요구사항
- 트레이드오프: 속도/단순성 vs 신뢰성 중 선택해야 함
> "카프카 설정 파일 보면서 '이게 뭔 설정이 이렇게 많아?' 했던 기억이 나네..."카프카가 강력한 이유는 유연성인데, 이게 동시에 가장 위험한 부분이기도 해.
### (3) 각 구성요소별 설정 방법 학습
다음 순서로 진행될 예정:
- 신뢰성 종류 정의 → 어떤 보장이 필요한지 명확히 하기 위함
- 복제 메커니즘 → 데이터 손실 방지를 위함
- 브로커/토픽 설정 → 사용 사례별 최적화를 위함
- 클라이언트 설정 → Producer/Consumer 신뢰성 보장을 위함
- 검증 방법 → 실제로 신뢰할 수 있는지 테스트하기 위함
>"브로커 3대로 시작했는데, 한 대 죽으니까 전체 시스템이 멈췄어. 그때 replication factor의 진짜 의미를 깨달았지. AWS에서 AZ 장애 겪어봤는데, 이 설정 덕분에 데이터 하나도 안 잃었어."
>"프로듀서 - Uber에서 배달 주문 데이터 처리할 때, acks=1로 설정했다가 브로커 장애시 주문이 사라지는 일이 있었어. 그 이후로는 무조건 acks=all로 설정해."
>"Consumer도 함정이 많아. auto commit 켜두고 처리 실패해도 offset이 커밋되면... 그 데이터는 영영 사라지는 거야."

>"신뢰성을 믿지 말고 측정해라. 내가 Netflix에서 배운 가장 중요한 교훈이야."

- 실무 최종 꿀팁
1. 항상 3개 브로커로 시작: "브로커 1-2개는 장난감이야"
2. acks=all 기본값으로 설정: "성능 최적화는 나중에, 안정성부터"
3. 수동 커밋 사용: "auto commit은 데이터 손실의 지름길"
4. 모니터링 먼저 구축: "장애는 새벽에 온다"
5. 카오스 엔지니어링 도입: "일부러 브로커 죽여보면서 테스트해라"
<br><br><br>








# 7.1 신뢰성보장
### (1) 신뢰성 보장(Reliability Guarantee) 개
- 관계형 DB의 ACID처럼, 카프카도 명확한 보장 사항이 있어야 믿고 쓸 수 있음
- 시스템이 어떤 상황에서 어떻게 동작할지 예측 가능해야 함
>"Goldman Sachs 트레이딩 시스템 마이그레이션할 때, 기존 Oracle DB의 ACID 보장에 익숙한 팀원들이 카프카의 '다른' 보장 방식을 이해하는 데 3주나 걸렸어."
<br>


### (2)  Kafka의 핵심 보장 사항들
- 유의사항
  - Kafka는 다양한 신뢰성 요구사항을 지원할 수 있는 유연한 구조.
  - 유연성 때문에 시스템이 실제로 신뢰할 수 없는 경우에도 신뢰한다고 착각할 수 있음.


### 보장1: 파티션 내 순서보장
```
python# 같은 파티션으로 보내면 순서 보장됨
producer.send('user-events', key='user123', value=event_a)  # offset: 100
producer.send('user-events', key='user123', value=event_b)  # offset: 101
# event_b는 항상 event_a 다음에 읽힘
```
<details>
  <summary>은행 계좌 시스템에서 순서가 중요한 이유</summary>

- 고객 계좌에 1,000달러가 있다고 가정해 봅시다. 다음 두 이벤트가 거의 동시에 발생했습니다:

* **이벤트 A:** 500달러 입금 (잔액: 1,000 → 1,500)
* **이벤트 B:** 300달러 출금 (잔액: 1,500 → 1,200)

- **만약 순서가 바뀌어서 이벤트 B가 먼저 처리된다면?**
* **출금 시도:** 1,000 - 300 = 700 (성공)
* **입금 처리:** 700 + 500 = 1,200

- 이 경우, 최종 결과는 같지만, **중간 과정에서 잔액 부족으로 출금이 거부될 수 있습니다.** 
- 고객 입장에서는 "돈 있는데 왜 출금이 안 되지?"라는 혼란을 겪게 됩니다.

### 순서대로 처리된다면?
* **입금 처리:** 1,000 + 500 = 1,500
* **출금 처리:** 1,500 - 300 = 1,200
- 거래순서중요
---
<br><br>

</details>
<br>

>"실무 팁: 순서가 중요한 데이터는 반드시 같은 key로 보내야 해. E-commerce 주문 처리할 때 이거 놓치면 '결제 → 주문취소' 순서가 바뀔 수 있어."
>"이 순서 보장 때문에 우리가 분산 시스템에서도 이벤트 순서를 믿고 비즈니스 로직을 짤 수 있는 거야. 만약 이게 없다면? 모든 애플리케이션에서 별도의 순서 관리 로직을 구현해야 하는 악이 시작되지."
<br>


### 보장 2: Committed 메시지 정의
- flush()
  - 버퍼를 비우는 동작
  - "보내긴 했다" 수준이지, 데이터가 안전하게 저장되었는지(복제 완료 여부)는 flush 자체로는 보장하지 않음

- commit의 의미
  - 데이터를 안전하게 저장했다고 선언하는 동작
  - 주체: 브로커 / Consumer
  - 의미: 카프카에서는 다음 두 경우에서 commit이 쓰임
    - (브로커) *commit* → 리더+팔로워 복제 완료 (ISR 만족)
      - 메시지가 영구히 저장된 상태
    - (컨슈머) *offset commit* → Consumer가 “나는 여기까지 읽었어” 라고 체크포인트 남기는 것
      - 다음에 재시작할 때 이어서 읽기 가능
      - offset commit안하면 컨슈머 재시작시 위치를 모름 → 데이터 유실 발생
      - 또는 다른 컨슈머가 파티션을 넘겨받았을때 어디까지 처리한줄 모르고 중복처리 될 가능성 있음.
      - 에러지점 찾기 어려움, 처음부터 다시하면 시간낭비 오짐  
      - 컨슈머 죽었다가 다시 살아났을때 정상작동하기 위해서 필요

  - **Offset Commit 없으면:**
    ```
    Consumer: "어... 나 어디까지 처리했지? 처음부터 다시?"
    → 1~1000번 주문 모두 다시 처리 (중복 결제!)
    ```
  - **Offset Commit 있으면:**
    ```
    Consumer: "아, 1000번까지 처리했구나. 1001번부터 시작하자"
    → 중복 처리 없음
    ```
  - 프로듀서 commit조건 설정
    ```
    # in-sync replica 설정에 따라 committed 시점이 달라짐
    topic_config = {
        'replication.factor': 3,
        'min.insync.replicas': 2  # 최소 2개 replica에 써져야 committed
    }
    ```
> "여기서 실수하기 쉬운 게, 디스크에 flush되어야 committed인 줄 아는데 아니야. in-sync replica들의 메모리에만 써져도 committed로 간주해."
> "이게 진짜 헷갈리는 부분이야. 많은 개발자들이 'committed = 디스크에 저장'이라고 착각해."
> "브로커 하나가 죽어도 데이터가 살아있다는 보장을 받는 거지."
> "Airbnb에서 예약 시스템 설계할 때, 이 보장 덕분에 여러 마이크로서비스가 동일한 예약 상태를 보게 할 수 있었어. 예약 서비스, 결제 서비스, 알림 서비스가 모두 같은 데이터를 기준으로 동작하는 거지."
<br>


### 보장 3:Producer ACK 레벨 선택
```
# 레벨별 ACK 전략
acks_strategies = {
    'acks=0': '보내고 잊기 (fire-and-forget)',  # 클릭 추적용, 저장했는지 전혀 확인하지 않아.
    'acks=1': '리더만 확인',                    # 일반 로그용  
    'acks=all': '모든 in-sync replica 확인'      # 중요 데이터용
}
```
> "Netflix에서 시청 기록 처리할 때는 acks=1로 충분했지만, 결제 데이터는 무조건 acks=all. 이게 현실적인 트레이드오프야."
> "실제로 Google에서 웹 검색 로그 처리할 때 이 방식 써. 검색 하나가 기록 안 되어도 전체 통계에는 영향 없으니까."
> "JPMorgan Chase에서 거래 데이터 처리할 때, acks=all 설정 때문에 평균 지연시간이 200ms 늘어났어. 하지만 연간 수십억 달러의 거래에서 데이터 손실 리스크를 0에 가깝게 만든 거니까 충분히 가치가 있었지."
<br>


### 보장4: Consumer는 Committed만 읽음
- 소비자는 커밋된 메시지만 읽을 수 있음.
- 카프카 내부에서 일어나는 일:
  1. 메시지가 리더 브로커에 도착 (아직 읽을 수 없음)
  2. Follower들이 복제 시작, 설정에 따라 최소 2개의 브로커에 저장되어야 "committed" 상태가   (여전히 읽을 수 없음)
  3. min.insync.replicas 조건 만족시 committed 상태로 변경
  4. 이제 Consumer가 읽을 수 있음
>만약 Consumer가 uncommitted 메시지도 읽을 수 있다면 어떻게 될까?
리더 브로커에만 저장된 결제 데이터를 Consumer가 읽어서 상품을 발송했는데, 그 직후 리더 브로커가 장애로 죽으면? 팔로워에는 복제가 안 되어있으니까 결제 데이터가 완전히 사라져. 하지만 상품은 이미 나갔어. 이게 바로 데이터 일관성이 깨지는 순간이야.
> 카프카가 committed 메시지만 읽게 하는 이유는 "이 데이터는 최소한 설정된 개수의 브로커에 안전하게 저장되어 있다"는 보장을 주기 때문이야. 브로커 하나가 죽어도 데이터는 살아있고, Consumer가 처리한 모든 메시지는 실제로 존재하는 데이터라는 확신을 줄 수 있어.

### 예시
```
"이제 이 모든 보장들이 어떻게 함께 작동해서 신뢰할 수 있는 시스템을 만드는지 보자."
- 전자상거래 주문 처리 시스템 예시:
- 같은 고객의 연속 이벤트들:

1. 장바구니에 상품 추가
2. 결제 진행
3. 재고 차감
4. 배송 준비

순서 보장의 영향:
  같은 key로 보내면 이 이벤트들이 정확한 순서로 처리돼. 
  만약 "재고 차감"이 "결제 진행"보다 먼저 처리되면? 
  결제 실패했는데 재고만 줄어드는 상황이 발생할 수 있어.

Committed 보장의 영향:
  결제 완료 이벤트가 committed 상태가 되어야 배송팀에서 읽을 수 있어. 
  이는 결제 데이터가 여러 브로커에 안전하게 저장되었다는 의미고, 
  브로커 장애가 발생해도 배송팀이 처리한 주문은 실제로 존재하는 주문이라는 확신을 줘.

ACK 레벨의 영향:
  결제 시스템에서는 acks=all을 써서 결제 완료 응답을 고객에게 보내기 전에 
  데이터가 안전하게 저장되었음을 보장해. 
  고객이 "결제 완료" 확인을 받았다면, 
  그 거래는 절대 사라지지 않는다는 약속을 지킬 수 있어.

Consumer 보장의 영향:
  배송팀의 Consumer는 committed 메시지만 읽으니까, 
  처리하는 모든 주문은 "실제로 결제가 완료되고 안전하게 저장된" 주문이라는 확신을 가질 수 있어. 
  브로커 장애로 인해 "존재하지 않는 주문"을 처리할 위험이 없지.


<Conclusion>
  "이 모든 보장들이 없다면? 분산 시스템에서 데이터 일관성을 유지하기 위해 
    애플리케이션 레벨에서 엄청나게 복잡한 로직을 구현해야 해. 
    카프카가 이런 복잡성을 인프라 레벨에서 해결해주는 거야."
```
<br>


### (3)  컨슈머 오프셋 오토커밋 (Consumer Offset Auto Commit)

- 컨슈머 쪽의 offset commit 설정
```
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("group.id", "payment-group");

// 오토커밋 ON
props.put("enable.auto.commit", "true");
// 커밋 주기 (기본: 5000ms)
props.put("auto.commit.interval.ms", "1000");

KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props, new StringDeserializer(), new StringDeserializer());

```
- Auto Commit 의미
  - **`enable.auto.commit` (자동 커밋)**
  - 카프카 컨슈머가 메시지 처리 후 자동으로 오프셋을 커밋하는 기능
  - "이 메시지까지 처리했습니다"를 카프카에 자동으로 알려주는 메커니즘
  - 개발자가 수동으로 commit() 호출할 필요 없음
  - 문제상황
    - 메시지 처리가 완료되기 전에 오프셋이 먼저 커밋될 수 있음. 이 상태에서 앱이 다운되면 해당 메시지는 처리되지 않고 영원히 누락됨.
    ```
     # 실제 동작:
     # 0초: poll() → 메시지 100개 읽음 (offset 1000~1099)
     # 1초: poll() → 메시지 200개 읽음 (offset 1100~1299) 
     # 2초: poll() → 메시지 150개 읽음 (offset 1300~1449)
     # 3초: 💥 오토커밋 발생! → "offset 1449까지 처리했음" 기록
     # 3초: poll() → 메시지 300개 읽음 (offset 1450~1749)
     # 6초: 💥 오토커밋 발생! → "offset 1749까지 처리했음" 기록
    ```
  >"이게 문제에요. 3초 동안 메시지 1000개를 읽었는데, 500번째에서 크래시가 나면? 카프카는 '1000개 다 처리했다'고 기록해버려요. 나머지 500개는 영영 처리 안 되는 거죠."


- 설정값

  - **`enable_auto_commit`**
    - True: 오토커밋 활성화 (기본값)
    - False: 수동 커밋 모드
  
  - **`auto_commit_interval_ms`**
    - 기본값: 5000 (5초)
    - 범위: 1000~30000 권장
    - 오토커밋 실행 주기
   
  - **`auto_offset_reset`**
    - earliest: 파티션 처음부터 읽기
    - latest: 최신 메시지부터 읽기 (기본값)
    - none: 에러 발생
  
- 설정값에 따른 의미
  - **`auto_commit_interval_ms = 1000`**
    - 1초마다 커밋 → 빠른 진행률 업데이트, 높은 오버헤드
    - 장애 복구 시 최대 1초치 메시지만 중복 처리

  - **`auto_commit_interval_ms = 10000`**
    - 10초마다 커밋 → 낮은 오버헤드, 느린 진행률 업데이트
    - 장애 복구 시 최대 10초치 메시지 중복 처리 가능

  - **`enable_auto_commit = False`**
    - 개발자가 직접 commit() 호출 필요
    - 정확한 시점에 커밋 가능
    - 메시지 처리 성공/실패에 따른 조건부 커밋 가능
- 수동으로 설정가능
- 예시 
- 로그 분석용 (오토커밋 적합)
  ```
  consumer = KafkaConsumer(
      'app-logs',
      enable_auto_commit=True,
      auto_commit_interval_ms=3000,
      max_poll_records=500
  )
  
  for message in consumer:
      # 간단한 로그 파싱 및 저장
      log_data = parse_log(message.value)
      elasticsearch.index('logs', log_data)
      # 자동으로 3초마다 커밋됨
  ```
- 결제 처리용 (수동커밋 필수)
  ```
  consumer = KafkaConsumer(
      'payments',
      enable_auto_commit=False,
      max_poll_records=1
  )
  
  for message in consumer:
      try:
          payment = message.value
          charge_result = process_payment(payment)
          save_to_db(payment['id'], charge_result)
          consumer.commit()  # 성공 시에만 커밋
      except Exception as e:
          logger.error(f"Payment failed: {e}")
          # 커밋하지 않음 → 재처리됨
  ```


<br>


### (4) 신뢰성 구축 시 트레이드오프
- 기본 보장만으로는 시스템이 완전히 신뢰할 수 있는 것은 아님.
- 신뢰성, 가용성, 처리량, 지연, 비용 등 여러 요소 사이 트레이드오프 필요.
- Kafka는 구성 파라미터를 통해 신뢰성 수준과 트레이드오프 조절 가능.

<html>

<body>

<!--StartFragment-->

사용 사례 | 신뢰성 | 가용성 | 처리량 | 지연시간 | 비용
-- | -- | -- | -- | -- | --
클릭 추적 | 낮음 | 높음 | 높음 | 낮음 | 낮음
사용자 활동 | 보통 | 높음 | 높음 | 보통 | 보통
결제 데이터 | 높음 | 보통 | 낮음 | 높음 | 높음

<!--EndFragment-->
</body>
</html>
<details>
  <summary>카프카 설정: 비즈니스 요구사항에 따른 두 가지 접근법 예시</summary>

### 케이스 1: 핀테크 결제 시스템 설정
> "결제 시스템이라... 일단 가장 중요한 질문부터. 돈이 사라지면? 회사 망해. SEC 감사 들어와. 고객 소송. 답은 정해졌어."

**Step 1: 비즈니스 임팩트 분석**
> "결제 데이터 하나 손실 = 평균 거래액 500달러 손실. 하루 10만 건 처리하니까... 0.1% 손실률이어도 하루 5만 달러 날아가는 거네. 이건 절대 안 돼."


**Step 2: 토픽 설정 결정**
> "일단 복제부터 확실히 하자."
* `replication.factor = 3`
* `min.insync.replicas = 2`
> "왜 3과 2? 브로커 하나 죽어도 서비스 계속되고, 두 개 죽으면 읽기는 되지만 쓰기는 중단. 금융권에서는 이게 표준이야. AWS 리전 하나 전체가 다운되는 경우까지 고려하면 5개로 해야 하지만... 지금은 스타트업이니까 일단 3개."


**Step 3: Producer 설정 - 여기서 진짜 고민 시작**
* `acks = 'all'`
> "이건 협상 불가. 결제 완료 응답을 고객에게 보낸 순간, 그 거래는 절대 사라지면 안 돼. acks=1으로 하면? 리더 브로커 죽는 순간 고객은 결제 완료 받았는데 우리 시스템에는 기록이 없는 상황 발생. 이거 하나로 스타트업 망할 수 있어."

* `retries = 2147483647`
* `enable.idempotence = True`
* `max.in.flight.requests.per.connection = 1`

> "retries를 MAX_INT로? 네트워크 일시 장애로 결제가 실패하면 안 되니까. 근데 재시도하면 중복 거래 위험이 있어서 idempotence를 켜야 해. 그리고 max.in.flight를 1로 해야 순서도 보장돼."

> "성능은? 초당 1,000건 정도 처리 예상인데, 이 설정으로도 충분해. 지연시간 200ms 정도 늘어나겠지만, 고객이 결제 버튼 누르고 3초 기다리는 거랑 3.2초 기다리는 거 차이 못 느껴."



**Step 4: Consumer 설정**

* `enable.auto.commit = False`
* `isolation.level = 'read_committed'`

> "auto commit? 절대 안 돼. 결제 처리 중간에 에러 나면? offset은 커밋되었는데 실제 결제는 실패. 그 결제는 영원히 처리 안 되는 거야. 수동으로 커밋해서 확실히 처리된 것만 커밋하자."

> "isolation.level을 read_committed로? 당연하지. uncommitted 데이터 읽어서 결제 처리했다가 그 데이터가 사라지면... 상상만 해도 끔찍해."
<br>

**최종 판단:**
"결과적으로 처리량은 조금 떨어지고 지연시간은 늘어나지만, 데이터 손실 위험은 거의 0에 가까워져. 스타트업에서 신뢰성 문제로 망하는 것보다는 초기에 조금 느리더라도 안전하게 가는 게 맞지."

---
<br>


### 케이스 2: 소셜미디어 클릭 추적 시스템 설정

> "이제 완전히 다른 시스템이야. 페이스북 같은 소셜미디어에서 '좋아요' 클릭 추적하는 거. 접근 방식이 180도 바뀌어야 해."

**Step 1: 비즈니스 임팩트 재평가**
> "클릭 하나 손실되면? 통계에서 0.000001% 오차 발생. 전체 트렌드에는 영향 없어. 하지만 초당 100만 건씩 들어오는데 지연시간 길어지면? 사용자 경험 망가져. 우선순위가 완전히 반대야."



**Step 2: 토픽 설정 - 가용성 우선**
* `replication.factor = 3`
* `min.insync.replicas = 1`

> "왜 min.insync.replicas를 1로? 리더만 살아있으면 계속 쓸 수 있게. 브로커 두 개 죽어도 서비스 중단 없이 데이터 수집 계속돼. 일부 데이터 손실보다는 서비스 가용성이 더 중요하니까."



**Step 3: Producer 설정 - 속도 최적화**
* `acks = 1`
> "acks=all로 하면? 팔로워 복제 기다리느라 처리량 절반으로 떨어져. 클릭 데이터에서 그 정도 신뢰성은 overkill이야. 리더만 확인하는 걸로 충분해."

* `batch.size = 65536`
* `linger.ms = 100`
* `compression.type = 'snappy'`

> "배치를 크게 잡고 100ms 기다려서 모아서 보내면? 네트워크 호출 횟수 1/100로 줄어들어. 처리량이 10배 늘어나지. 100ms 지연? 클릭 추적에서는 실시간일 필요 없으니까 문제없어."

> "압축은? snappy가 CPU 적게 쓰면서도 압축률 좋아. 네트워크 대역폭 50% 절약되고, AWS 데이터 전송 비용도 절반으로 줄어들어."




**Step 4: Consumer 설정 - 처리량 우선**

* `enable.auto.commit = True`
* `auto.commit.interval.ms = 5000`

> "이번에는 auto commit을 켜자. 클릭 데이터 몇 개 중복 처리되거나 손실되어도 큰 문제 없어. 대신 Consumer 코드가 단순해지고 처리 속도가 빨라져."

* `fetch.min.bytes = 50000`
* `fetch.max.wait.ms = 500`

> "한 번에 많은 메시지를 가져오게 설정. 네트워크 오버헤드 줄이고 처리량 극대화하는 거야."
<br>

**최종 판단:**
> "결과적으로 초당 100만 건 처리 가능하고, 평균 지연시간 150ms. 데이터 손실률은 0.01% 정도 되겠지만, 클릭 추적에서는 전혀 문제없어. 오히려 인프라 비용이 50% 절약되는 게 더 중요하지."

---

### 두 시스템의 대비되는 선택 이유

**결제 시스템의 핵심 가치**

* **정확성 > 속도:** 느려도 되니까 정확해야 함
* **신뢰성 > 비용:** 비싸도 되니까 안전해야 함
* **일관성 > 가용성:** 서비스 잠깐 중단되어도 데이터 일관성 유지

**클릭 추적 시스템의 핵심 가치**

* **속도 > 정확성:** 정확하지 않아도 되니까 빨라야 함
* **비용 > 신뢰성:** 안전하지 않아도 되니까 저렴해야 함
* **가용성 > 일관성:** 데이터 좀 틀려도 서비스는 계속되어야 함

> "5년간 실리콘밸리에서 일하면서 깨달은 건, 똑같은 기술이어도 비즈니스 요구사항에 따라 완전히 다르게 설정해야 한다는 거야. 정답은 없어. 상황에 맞는 최적해만 있을 뿐이지."
<br><br>
</details>
<br><br><br>












# 7.2 복제(Replication)
> "복제 메커니즘... 이게 카프카 신뢰성의 핵심이야. 두 프로젝트 모두 이 복제 설정을 어떻게 하느냐에 따라 운명이 갈려."
- 목적: Kafka의 메시지 내구성과 고가용성을 보장하기 위한 복제 시스템 이해
- 핵심: 메시지를 여러 브로커에 복제하여 장애 시에도 데이터 손실 없이 서비스 지속
- (참고)Kafka 4.0.0: 2025년 3월 18일 릴리즈

## (1) 기본구조와 파티션
### 파티션의 역할
- 토픽은 여러 파티션으로 분할됨
- 각 파티션은 단일 디스크에 저장
- 파티션 내에서 이벤트 순서 보장
- 상태: Online (사용가능) 또는 Offline (사용불가)

> "파티션이 기본 단위인 이유는 확장성 때문이야. 토픽 전체를 복제하면 너무 무거워지니까, 파티션 단위로 나눠서 각각 독립적으로 복제하는 거지. 이렇게 하면 특정 파티션만 문제가 생겨도 다른 파티션은 영향 없이 계속 동작할 수 있어."

<br><br>




## (2) 리더-팔로워구조
### 복제본(Replica) 관리
- 각 파티션마다 여러 복제본 존재
- 그 중 하나가 리더(Leader) 역할
- 나머지는 팔로워(Follower) 역할
<br>

### 데이터 흐름
- 프로듀서 → 리더 복제본에만 메시지 전송
- 컨슈머 → 주로 리더 복제본에서 메시지 읽기
- 팔로워 → 리더로부터 지속적으로 데이터 동기화

> "왜 리더 하나에만 쓰고 읽을까? 일관성 때문이야. 만약 여러 복제본에 동시에 쓰면 순서가 꼬일 수 있거든. 리더 하나를 통해서만 처리하면 순서가 보장되고, 팔로워들은 그 순서 그대로 따라가기만 하면 돼."

<br><br>

## (3) 동기화 상태관리(In-Sync Replica)
### In-Sync 조건
**팔로워 복제본이 동기화 상태로 인정받으려면:**
- [1] ZooKeeper 세션 유지
  - 최근 6초 내 하트비트 전송 (설정 가능)
- [2] 메시지 fetch 활동
  - 최근 10초 내 리더로부터 메시지 가져오기 (설정 가능)
- [3] 지연시간 기준
  - 최근 10초 내 최신 메시지까지 따라잡기 (설정 가능)
> "여기서 중요한 건 단순히 메시지를 받고 있다고 끝이 아니라는 거야. 10초 안에 최신까지 따라잡아야 해. 왜냐하면 네트워크가 느려서 계속 뒤쳐지는 상황이면, 그 복제본은 신뢰할 수 없거든. 실제 장애 상황에서 그런 복제본이 리더가 되면 데이터 손실이 발생할 수 있어."

<br>

### Out-of-Sync 상황
**다음 경우 복제본이 동기화에서 제외됨:**
- ZooKeeper 연결 끊김
- 메시지 fetch 중단
- 10초 내 따라잡기 실패
<br><br>

## (4) 리더 선출과 장애복구
### 리더 장애 시 처리
- 현재 리더가 사용 불가능해짐
- In-sync 복제본 중에서 새 리더 선출
- 새 리더가 읽기/쓰기 처리 시작
<br>

### 복구 과정
- Out-of-sync 복제본의 재동기화
- ZooKeeper 재연결
- 최신 메시지까지 따라잡기
- 일시적 네트워크 문제는 빠르게 복구
- 브로커 장기 다운 시에는 오랜 시간 소요

> "리더 선출이 자동으로 이뤄지는 게 Kafka의 핵심 강점이야. 운영자가 수동으로 개입할 필요가 없어. 하지만 여기서 중요한 건 In-sync 복제본 중에서만 리더를 선출한다는 거지. Out-of-sync 복제본이 리더가 되면 데이터 손실 위험이 있거든."

<br><br>




## (5) 성능과 트레이드 오프
### 성능 영향
- In-sync 복제본들이 모든 메시지를 받을 때까지 대기
- 약간 뒤처진 In-sync 복제본도 전체 성능에 영향
- Out-of-sync가 되면 더 이상 기다리지 않음
<br>

### 위험 요소
- Out-of-sync 복제본 증가 → 유효 복제 팩터 감소
- 다운타임 및 데이터 손실 위험 증가
> "이게 운영할 때 항상 모니터링해야 하는 부분이야. In-sync 복제본 수가 계속 줄어들고 있다면, 클러스터에 문제가 있다는 신호거든. 복제 팩터가 3이었는데 In-sync가 1개만 남으면, 그 브로커만 죽어도 데이터 손실이야."

<br><br>



## (6) 과거 문제점과 개선사항
### 구버전 문제점 (Kafka 2.5.0 이전)
- 복제본이 In-sync와 Out-of-sync 사이를 빈번하게 전환
- 주요 원인:
  - 큰 최대 요청 크기
  - 큰 JVM 힙 크기
  - 긴 GC(Garbage Collection) 일시정지
<br>

### 현재 개선된 점
- Apache Kafka 2.5.0+ 기본 설정으로 문제 대부분 해결
- JVM 8+ 의 G1 가비지 컬렉터 사용
- ZooKeeper 연결 타임아웃 및 복제본 지연 설정 최적화
- 복제 프로토콜의 신뢰성 대폭 향상
> "옛날에는 정말 골치 아팠어. 복제본이 계속 들락날락하면서 클러스터가 불안정했거든. 지금은 기본 설정만 써도 웬만하면 안정적이야. 하지만 대용량 메시지 처리할 때는 여전히 튜닝이 필요할 수 있어. GC 튜닝이 특히 중요하지."

<br><br>





## (7) 최신 업데이트 및 변경사항 (2025)
### Kafka 4.0 주요 변화 (2025년 3월 출시)

- ZooKeeper 완전 제거
  - KRaft가 기본 메타데이터 관리 방식으로 단일화
  - 더 이상 ZooKeeper 클러스터 운영 불필요
  - 배포 및 관리 복잡성 대폭 감소


- Java 버전 요구사항 변경
  - Kafka 클라이언트/스트림즈: Java 11+ 필수
  - Kafka 브로커/커넥트/도구: Java 17+ 필수
  - Java 8 지원 완전 중단


- 새로운 컨슈머 리밸런스 프로토콜
  - KIP-848로 "stop-the-world" 리밸런스 제거
  - 점진적 파티션 할당으로 성능 향상

> "4.0이 게임체인저야. ZooKeeper 없애면서 운영 복잡도가 절반으로 줄었어. 그리고 리밸런스 개선은 정말 필요했던 부분이야. 예전엔 컨슈머 그룹에 새 인스턴스 하나 추가하면 전체 그룹이 멈췄는데, 이제는 점진적으로 처리되니까 downtime이 확 줄었지."

<br>



### 필요없어진 구성요소들
- ZooKeeper 관련 모든 설정 및 모니터링
  - ZooKeeper 하트비트 체크 불필요
  - ZooKeeper 연결 설정 제거
  - ZooKeeper 장애 대응 프로세스 불필요
- 구버전 호환성 부분
  - Kafka 2.1 이전 버전과의 호환성 지원 중단
  - 메시지 포맷 v0, v1 지원 제거
  - MirrorMaker 1.0 지원 종료

> "솔직히 ZooKeeper 모니터링 안 해도 되는 게 제일 좋아. 예전엔 Kafka 문제인지 ZooKeeper 문제인지 구분하느라 디버깅이 복잡했는데, 이제는 Kafka만 보면 돼. 운영 관점에서 정말 단순해졌어."
<br>




### 새로운 모니터링 포인트 (KRaft 환경)
- KRaft 컨트롤러 상태
  - 활성 컨트롤러 선출 상태
  - 메타데이터 토픽 복제 지연
  - 컨트롤러 quorum 상태

- 기존 복제 모니터링
  - In-sync 복제본 수 (여전히 중요)
  - 복제본 지연시간 (10초 기준)
  - GC 일시정지 시간

> "KRaft로 넘어가면서 모니터링 포인트가 바뀌었어. ZooKeeper 대신 KRaft 컨트롤러 상태를 봐야 하고, 메타데이터 토픽의 복제 상태도 체크해야 해. 하지만 전반적으로는 모니터링할 게 줄었지."

<br><br>





## (8) 실무 마이그레이션 가이드
### 업그레이드 준비사항

- Java 버전 업그레이드
  - 클라이언트: Java 11+
  - 브로커: Java 17+
- ZooKeeper → KRaft 마이그레이션
  - 무중단 마이그레이션 프로세스 지원
  - Dual-write 모드를 통한 안전한 전환
  - 롤백 가능 (finalize 전까지)



### 마이그레이션 단계

1. 준비: KRaft 컨트롤러 설정
2. Dual-write: ZooKeeper와 KRaft 동시 운영
3. 검증: 성능 및 안정성 확인
4. Finalize: ZooKeeper 연결 완전 해제

> "마이그레이션이 생각보다 까다로워. 특히 대규모 프로덕션 환경에서는 단계별로 신중하게 진행해야 해. Dual-write 모드에서 충분히 검증한 후에 finalize 하는 게 중요하고, 롤백 계획도 미리 세워둬야 하지."

<br><br><br>









# 7.3 브로커 설정
## 1. 개요
- 브로커 설정변수 3개
- 목적: 메시지 안정성과 성능 간의 최적 균형점 찾기
- 핵심: 브로커 레벨(전체 기본값) + 토픽 레벨(개별 조정) 조합 설정
<details>
<summary>브로커 3가지 설정값 의미</summary>

<br>
   
1. Replication Factor (**`replication.factor`**, **`default.replication.factor`**)
- 의미: 각 파티션 데이터를 몇 개의 복제본(replica)으로 유지할지 결정.
- 값이 크면 → 더 많은 브로커에 복사 → 가용성과 내구성 증가
- 값이 작으면 → 저장/네트워크 비용 감소, 하지만 장애 시 데이터 손실 위험 증가
- 핵심: 복제본 개수를 정해 데이터 안정성과 비용을 조율하는 설정
<br>

2. Unclean Leader Election (**`unclean.leader.election.enable`**)
- 의미: 리더가 죽었을 때, 동기화되지 않은(replication lag 있는) 복제본을 리더로 승격할 수 있는지 여부.
- `false`(기본값) → Out-of-sync replica는 리더가 될 수 없음 → 데이터 유실 방지, 가용성 감소
- `true`→ Out-of-sync replica도 리더 가능 → 가용성 증가, 데이터 유실 위험 증가
- 핵심: 가용성과 데이터 정합성 중 어느 쪽을 우선할지 결정하는 설정
<br>

3. Minimum In-Sync Replicas (**`min.insync.replicas`**)
- 의미: 메시지를 커밋(확정)하려면 최소 몇 개의 replica가 동기화 상태여야 하는지 정의.
- 예: 3개 replica 중 2개가 in-sync여야 함 (**`min.insync.replicas=2`**)
  - 정상적으로 2개 이상 동기화 → 메시지 기록 가능
  - 1개만 남으면 → 쓰기 불가(읽기만 가능) → 데이터 유실 방지
- 값이 크면 → 데이터 안정성 증가, 가용성 감소
- 핵심: 안전하게 쓰기 위해 필요한 최소 복제본 수를 보장하는 설정
<br>

</details>

<br><br>




## 2. 핵심 구성 파라미터
### (1) 복제 계수 (Replication Factor)
- **설정명:**
    - `replication.factor` (토픽)
    - `default.replication.factor` (브로커 기본값)
- **정의:** 각 파티션 데이터를 몇 개의 복제본(copy)으로 저장할지 지정
- **효과:** 복제 계수가 $N$일 경우, $N-1$개의 브로커 장애까지 서비스 중단 없이 데이터 처리 가능
- **주요 고려사항 (Trade-off 관계)**
    - **가용성 (Availability):** 높을수록 향상됨 (복제본 1개는 브로커 재시작만으로도 서비스 불가)
    - **내구성 (Durability):** 높을수록 데이터 유실 확률 감소
    - **처리량 (Throughput):** 높을수록 복제를 위한 브로커 간 네트워크 트래픽 증가 (예: 3개 복제 시 원본 데이터의 2배 트래픽 발생)
    - **지연 시간 (Latency):** 모든 동기화 복제본에 쓰기가 완료되어야 하므로 이론적으로 증가 가능
    - **비용 (Cost):** 복제본 수에 비례하여 스토리지 및 네트워크 비용 증가
- **배치 전략:**
    - `broker.rack` 설정을 통해 복제본을 물리적으로 다른 랙(Rack)이나 클라우드의 가용 영역(AZ)에 분산 배치하여 안정성 극대화
<br>

### (2) 정결하지 못한 리더 선출 (Unclean Leader Election)
- **설정명:** `unclean.leader.election.enable` (브로커 레벨)
- **기본값:** `false` (데이터 정합성을 위해 변경을 강력히 비권장)
- **목적:** 리더 파티션 장애 시, 동기화된(in-sync) 팔로워가 **하나도 없을 경우**의 동작 방식을 결정
- **발생 시나리오:**
    - 다수의 팔로워가 다운된 상태에서 리더마저 다운되는 경우
    - 네트워크 문제 등으로 팔로워들이 리더를 따라가지 못해 동기화 그룹(ISR)에서 이탈된 상태에서 리더가 다운되는 경우
- **설정값에 따른 동작:**
    - **`false` (기본값):** 정합성 우선. 동기화 상태였던 기존 리더 또는 다른 팔로워가 복구될 때까지 파티션을 오프라인으로 유지. **데이터 유실 없음.**
    - **`true`:** 가용성 우선. 동기화되지 않은(out-of-sync) 팔로워를 리더로 선출하여 즉시 서비스를 재개. 이 경우, 이전 리더에만 존재하던 **데이터가 영구적으로 유실될 위험**이 있고, 데이터 불일치를 유발함.
<br>

### (3) 최소 동기화 복제본 수 (Minimum In-Sync Replicas)
- **설정명:** `min.insync.replicas` (토픽 및 브로커 레벨)
- **정의:** 프로듀서의 쓰기 요청이 '성공(committed)'으로 처리되기 위해 필요한 최소 동기화 복제본(ISR, In-Sync Replicas)의 수
- **동작:**
    - `replication.factor`가 3, `min.insync.replicas`가 2인 경우, 최소 2개의 복제본이 동기화 상태여야 쓰기 가능
    - 만약 동작 중인 동기화 복제본의 수가 이 값보다 적어지면, 브로커는 쓰기 요청을 거부하고 `NotEnoughReplicasException`을 발생시킴
    - 이때, 해당 파티션은 새로운 데이터 쓰기는 불가능하고 읽기만 가능한 상태가 됨
- **효과:** 데이터가 단 하나의 리더에만 기록된 후 해당 리더에 장애가 발생해 데이터가 유실되는 상황을 방지하여 데이터 내구성을 극대화 (프로듀서의 `acks=all` 옵션과 함께 사용 시 가장 강력한 보장 제공)
<br><br>


## 3. 보조 구성 파라미터

### (1) 복제본 동기화 유지 관련
- `zookeeper.session.timeout.ms`: 브로커가 주키퍼와의 하트비트를 보내지 못했을 때, 주키퍼가 해당 브로커를 비정상으로 판단하기까지 대기하는 시간
- `replica.lag.time.max.ms`: 팔로워 복제본이 리더를 따라잡지 못하고 뒤처지는 것을 허용하는 최대 시간. 이 시간을 초과하면 해당 팔로워는 동기화 그룹(ISR)에서 제외됨
<br>

### (2) 디스크 저장 정책 관련
- **기본 동작:** 카프카는 성능 향상을 위해 OS의 페이지 캐시(Page Cache)에 데이터를 기록하고, 디스크 파일에 대한 물리적 동기화(fsync)는 OS에 위임
- **강제 동기화 설정:**
    - `flush.messages`: 지정된 메시지 개수마다 디스크 동기화 수행
    - `flush.ms`: 지정된 시간 간격마다 디스크 동기화 수행
- **주의사항:** 강제 동기화 설정은 디스크 I/O를 빈번하게 발생시켜 카프카의 전체적인 처리량과 성능을 크게 저하시킬 수 있으므로 신중하게 사용해야 함
<br><br><br>







# 7.4 신뢰성 있는 시스템에서 프로듀서 사용법
### (1) 프로듀서 설정의 중요성
- 브로커를 아무리 안정적으로 설정해도, 프로듀서 설정이 잘못되면 전체 시스템에서 데이터가 유실될 수 있음.
- **데이터 유실 시나리오 예시**
    - **사례 1 (`acks=1` 사용 시):** 프로듀서가 리더에게 메시지를 보내고 '성공' 응답을 받음. 하지만 리더가 팔로워에게 복제하기 직전에 다운됨. 새로운 리더가 선출되지만 해당 메시지는 없음. 프로듀서 애플리케이션은 성공으로 인지했지만 메시지는 유실됨.
      ```
      문제 상황 타임라인:
        1.프로듀서가 파티션 리더에게 메시지 전송
        2.리더가 로컬 로그에 메시지 저장
        3.리더가 프로듀서에게 "성공" 응답 전송 ✅
        4.리더가 팔로워들에게 복제하기 직전에 크래시 💥
        5.새로운 리더 선출 (기존 팔로워 중 하나)
        6.새 리더에는 해당 메시지가 없음 - 데이터 유실
      ```
      > "아, 이거 완전 클래식한 데이터 유실 케이스네. 프로듀서는 성공했다고 생각하는데 실제로는 메시지가 날아간 거야. 리더가 ack 보내고 죽어버리면 게임 오버지.운영 중에 이런 일 한 번 겪어보면 절대 acks=1 안 쓰게 됨."
    - **사례 2 (오류 미처리 시):** `acks=all`로 설정하고 메시지를 보냈으나, 리더 선출 과정이라 브로커가 '리더 사용 불가' 오류를 반환함. 프로듀서가 이 오류에 대해 재시도 로직 없이 처리를 종료하면, 브로커는 메시지를 받은 적이 없으므로 해당 메시지는 유실됨.
      ```
      문제 상황 시퀀스:
        1.리더 선출 진행 중 (30초 소요)
        2.프로듀서가 메시지 전송 시도
        3.브로커가 NotLeaderForPartitionException 반환
        4.프로듀서가 예외 로그만 찍고 포기
        5.메시지 영구 유실
      ```
    - **사례3 후처리없는 코드(fire and forget)**
      - 잘못된코드
        ```
        # 조용한 실패 - 가장 위험
        producer.send('my-topic', value=data)
        # callback 없이 fire-and-forget
        # 실패해도 모름!
        ```
      - 잘된 코드
        ```
        producer.send('my-topic', value=data).get()  # 안전
  
        # 안전한 코드 - 동기 확인
        try:
            future = producer.send('my-topic', value=data)
            result = future.get(timeout=30)  # 이 줄이 핵심!
            print(f"전송 성공! offset: {result.offset}")
        except Exception as e:
            print(f"전송 실패: {e}")
            # 실패 처리 로직
  
        # 안전한 코드 - 비동기 콜백
        def on_success(record_metadata):
            print(f"전송 성공! offset: {record_metadata.offset}")
        
        def on_error(exception):
            print(f"전송 실패: {exception}")
            # 실패 처리 로직
        
        # 콜백과 함께 전송
        future = producer.send('my-topic', value=data)
        future.add_callback(on_success)
        future.add_errback(on_error)
        ```
      
- **핵심 원칙**
    - **(1) `acks` 설정:** 신뢰성 요구사항에 맞는 `acks` 옵션을 사용해야 함.
    - **(2) 오류 처리:** 설정과 코드 양쪽에서 오류를 올바르게 처리해야 함.
<br>

### (2) 전송 확인 (Acknowledgements)
- **`acks=0`**
    - 프로듀서가 네트워크로 메시지를 전송하면 즉시 성공으로 간주 (Fire-and-forget).
    - 브로커의 성공/실패 여부를 전혀 알 수 없어 데이터 유실 위험이 매우 높음.
    - 프로듀서 지연 시간은 가장 짧지만, 종단 간(end-to-end) 지연 시간은 개선되지 않음 (컨슈머는 복제 완료 후 소비 가능).
- **`acks=1`**
    - 리더 복제본이 메시지를 수신하고 기록하면(디스크 동기화 보장 안됨) 성공 응답을 보냄.
    - 리더가 응답 직후, 팔로워에게 복제 전 다운되면 데이터 유실 가능.
- **`acks=all`** (또는 `-1`)
    - 리더가 모든 In-Sync Replica(ISR)로부터 메시지를 확인한 후 성공 응답을 보냄.
    - 가장 강력한 데이터 보장 옵션으로, 데이터 유실 가능성이 가장 낮음.
    - `min.insync.replicas` 설정과 함께 사용하여 '최소 몇 개 복제본에 저장될지'를 제어할 수 있음.
    - 프로듀서 지연 시간은 가장 김.
<br>

### (3) 프로듀서 재시도 설정
- **재시도 필요한 상황**
  - 네트워크 지연, 브로커 장애, 리더변경 등 일시적오류 발생
  - 재시도↑ → 안정성↑(유실위험감소),성능↓(초당처리량) (트레이드오프)
    ```
    처리 흐름:
    1.프로듀서가 메시지 전송 시도
    2.오류 발생 시 재시도 가능/불가능 판단
    3.재시도 가능하면 설정된 정책에 따라 재시도
    4.최대 시간 초과 또는 성공까지 반복
    ```
- **재시도관련 설정값**
  - a.재시도횟수 설정,간격
    - `retries` :전송 실패 시 최대 몇 번까지 재시도할지 설정, 무한대면 메모리부족위험, 적으면 메시지유실 (3~10회적당)(
    - `retry.backoff.ms` : 재시도 사이의 대기 시간 (밀리초) ,즉시 재시도하면 브로커에 부하를 주고, 같은 오류가 반복될 가능성이 높음
    - max_in_flight_requests_per_connection =5 : 재시도 중인 메시지 1개가 있어도 나머지 4개는 처리 가능(비동시처리 최대 task수)
    ```
      producer_config = {
        'retries': 2147483647,  # 기본값: MAX_INT (사실상 무한대)
        'retry.backoff.ms': 100,  # 기본값: 100ms (재시도 간격) 긴간격(5000)
    }
    ```
  - b.타임아웃
    - `delivery.timeout.ms` : 메시지 전송을 완전히 포기하기까지의 총 시간, 이 시간 안에 retries 횟수만큼 재시도를 반복함
      - 짧으면: 빠른 실패 감지, 일시적 장애 시 메시지 유실 위험
      - 길면: 메시지 유실 방지, 장애 시 애플리케이션 블로킹
    - `request.timeout.ms`  : 개별 요청(한 번의 전송 시도)이 응답을 기다리는 최대 시간
      - delivery.timeout.ms = request.timeout.ms × retries + (retry.backoff.ms × retries)
    - `max.block.ms`    : send() 메서드가 블로킹될 수 있는 최대 시간(버퍼가 가득 찬 경우, 메타데이터 가져오는경우)
    ```
    producer_config = {
        'delivery.timeout.ms': 120000,  # 기본값: 120초
        'request.timeout.ms': 30000,    # 기본값: 30초
        'max.block.ms': 60000,          # 기본값: 60초
    }
    ```
  - c.멱등성 설정
  - enable.idempotence :  프로듀서가 중복 메시지 전송을 방지하도록 설정
    - 프로듀서가 각 메시지에 sequence_number값을 브로커로 전달. 브로커가 중복을 감지(True-성능 오버헤드 발생)
  - max.in.flight.requests.per.connection : 브로커로부터 응답을 받기 전에 전송할 수 있는 최대 요청 수,
    - `1` : 순서중시, 성능저하
    - `5` : 높은 처리량, 재시도시 순서 바뀔수 있음
    ```
    producer_config = {
        'enable.idempotence': False,  # 기본값: False
        'max.in.flight.requests.per.connection': 5,  # 기본값: 5
    }
    ```
    - 의존성이 있는 설정값
      - `enable.idempotence=true`
        ```
        acks='all' 강제 설정
        retries > 0 강제 설정
        max.in.flight.requests.per.connection ≤ 5 제한
        ```
      - `delivery.timeout.ms`
        ```
        delivery.timeout.ms ≥ linger.ms + request.timeout.ms
        ```

<details>
  <summary>실제 설정과 대응</summary>
  
### 상황 1: 메시지 유실 발생
```
# 문제 상황 재현 - 이런 설정은 메시지 유실을 유발할 수 있다
risky_config = {
    'retries': 0,  # 재시도 안 함
    'acks': '0',   # 확인 안 함
}

# 해결책 - 안정성 강화
safe_config = {
    'retries': 10,
    'acks': 'all',
    'enable_idempotence': True,
}
```
상황 2: 성능 저하
```
# 성능 문제 설정 - 이건 너무 보수적이라 느릴 수 있다
slow_config = {
    'max_in_flight_requests_per_connection': 1,
    'retry_backoff_ms': 5000,  # 5초씩 대기
    'delivery_timeout_ms': 600000,  # 10분
}

# 성능 개선 - 안정성은 유지하면서 속도 향상
optimized_config = {
    'max_in_flight_requests_per_connection': 5,
    'retry_backoff_ms': 100,
    'delivery_timeout_ms': 120000,  # 2분
    'enable_idempotence': True,  # 중복 방지는 유지
}
```
상황 3: 메모리 부족(프로듀서 버퍼)
```
# 메모리 문제 유발 설정 - 이건 버퍼가 계속 쌓일 수 있다
memory_issue_config = {
    'retries': 2147483647,  # 무한 재시도
    'delivery_timeout_ms': 86400000,  # 24시간
    'max_block_ms': 86400000,  # 24시간 블로킹
    'buffer_memory': 134217728,  # 128MB
}

# 메모리 안전 설정
memory_safe_config = {
    'retries': 5,
    'delivery_timeout_ms': 300000,  # 5분
    'max_block_ms': 10000,  # 10초만 블로킹
    'buffer_memory': 33554432,  # 32MB
}
```  
</details>
<details>
  <summary>권장 설정 예시</summary>

### 보수적설정
```
# 절대 메모리 부족이 일어나면 안 되는 시스템
ultra_safe_config = {
    'retries': 3,  # 적은 재시도
    'delivery_timeout_ms': 30000,  # 30초
    'max_block_ms': 1000,  # 1초만 블로킹
    'buffer_memory': 16777216,  # 16MB만 사용
    'batch_size': 8192,  # 작은 배치 크기
    'linger_ms': 0,  # 즉시 전송
}
```
### 균형설정(실무권장)
```
# 대부분의 상황에서 안전한 설정
balanced_safe_config = {
    'retries': 5,
    'delivery_timeout_ms': 120000,  # 2분
    'max_block_ms': 10000,  # 10초 블로킹
    'buffer_memory': 33554432,  # 32MB
    'batch_size': 16384,
    'linger_ms': 100,
    
    # 안전장치 추가
    'enable_idempotence': True,
    'acks': 'all',
}
```
</details>




### (4) 재시도 가능여부를 판단
- 프로듀서는 재시도 가능여부를 스스로 판단
- **어떻게?**
  - 브로커가 응답으로 에러코드 전송
  - 클라이언트 라이브러리에 에러코드별 정책이 미리 내장됨

- **재시도 가능 오류 (Retriable Errors)**
    - 프로듀서가 자동으로 처리할 수 있는 일시적인 오류.
    - 예: `LEADER_NOT_AVAILABLE` (리더가 일시적으로 없는 경우로, 재시도 시 해결 가능).
    - 브로커-1
- **재시도 불가능 오류 (Non-retriable Errors)**
    - 재시도해도 해결되지 않는 영구적인 오류.
    - 예: `INVALID_CONFIG` (설정 오류로, 메시지를 다시 보낸다고 해결되지 않음).
<br>

### (5) 추가적인 오류 처리 (개발자 책임)
- 프로듀서의 자동 재시도로 해결되지 않는 오류들은 개발자가 직접 코드에서 처리해야 함.
- **처리 대상 오류 종류**
    - 재시도 불가능한 브로커 오류 (메시지 크기 초과, 인증 오류 등).
    - 전송 전 발생 오류 (메시지 직렬화 오류 등).
    - 프로듀서 재시도 소진 또는 타임아웃 발생 시.
    - 재시도 중 프로듀서 내부 버퍼가 가득 찼을 때.
- **오류 처리 전략 (애플리케이션 요구사항에 따라 결정)**
    - 잘못된 메시지는 버리기.
    - 오류를 로그로 기록하기.
    - 소스 시스템으로부터 메시지 읽기를 중단하기.
    - 소스 시스템에 역압력(Back pressure)을 가해 잠시 메시지 전송 중단 요청.
    - 실패한 메시지를 로컬 디스크의 별도 디렉토리에 저장.
<br><br><br>





# 7.5 신뢰성 있는 시스템을 위한 컨슈머 사용법
<br>

### (1) 컨슈머의 역할과 오프셋 커밋
- **컨슈머의 기본 보장:** 컨슈머는 모든 복제본에 쓰기가 완료된 '커밋된 메시지(Committed Messages)'만 읽을 수 있으므로, 데이터 일관성이 보장됨.
- **컨슈머의 핵심 책임:** 어떤 메시지까지 읽고 처리했는지를 추적하는 '오프셋 커밋(Offset Commit)'을 관리하는 것.
- **데이터 유실 위험:** 메시지를 읽었지만 **완전히 처리하기 전에** 오프셋을 커밋하는 것이 메시지 유실의 주된 원인. 컨슈머 재시작 또는 리밸런싱 시, 처리되지 않은 메시지를 건너뛰게 됨.
- **용어 구분:**
    - **커밋된 메시지:** 모든 동기화 복제본(ISR)에 기록되어 컨슈머가 읽을 수 있는 메시지.
    - **커밋된 오프셋:** 컨슈머가 특정 오프셋까지의 모든 메시지를 성공적으로 처리했다고 카프카에 알리는 값.
<br>

### (2) 신뢰성 있는 처리를 위한 주요 설정
- **`group.id`**
    - 동일한 `group.id`를 가진 컨슈머들은 하나의 그룹으로 묶여, 구독한 토픽의 파티션을 나누어 처리함 (메시지 분산 처리).
    - 토픽의 모든 메시지를 각 컨슈머가 개별적으로 수신해야 한다면, 고유한 `group.id`를 사용해야 함 (메시지 브로드캐스팅).
- **`auto.offset.reset`**
    - 커밋된 오프셋이 없거나, 요청한 오프셋이 브로커에 존재하지 않을 때 컨슈머의 동작을 결정.
    - **`earliest`:** 가장 처음부터 메시지를 읽음. 중복 처리가 발생할 수 있으나 데이터 유실을 최소화.
    - **`latest`:** 가장 마지막부터 메시지를 읽음. 중복 처리는 최소화되지만, 컨슈머가 동작하지 않는 동안 쌓인 메시지를 놓칠 수 있음 (데이터 유실).
- **`enable.auto.commit`**
    - 오프셋 커밋을 자동으로 할지, 수동으로 할지 결정하는 중요한 선택.
    - **`true` (자동 커밋):** 구현이 간편함. `poll()` 루프 내에서 모든 처리가 끝나는 단순한 경우에 유용. 하지만 처리가 완료되기 전에 커밋이 발생하여 데이터가 유실될 위험이 있고, 중복 처리 제어가 어려움.
    - **`false` (수동 커밋):** 처리가 완료된 시점을 명확히 보장해야 하는 복잡한 로직(예: 별도 스레드 처리)에서는 반드시 사용해야 함.
- **`auto.commit.interval.ms`**
    - 자동 커밋(`enable.auto.commit=true`) 사용 시, 얼마나 자주 커밋할지를 결정 (기본값 5초).
    - 주기를 짧게 하면 중복 처리 가능성은 줄지만, 브로커에 대한 오버헤드가 증가함.
<br>

### (3) 명시적 오프셋 커밋 (수동 커밋)
- **메시지 처리 후 항상 커밋:** 오프셋 커밋은 반드시 메시지에 대한 모든 처리가 성공적으로 완료된 후에 수행해야 함.
- **커밋 빈도는 트레이드오프:**
    - 커밋은 `acks=all` 프로듀싱과 유사하게 성능 오버헤드가 있는 작업.
    - 너무 잦은 커밋(예: 메시지마다 커밋)은 성능을 저하시키고, 너무 드문 커밋은 장애 시 중복 처리되는 데이터 양을 늘림.
- **정확한 오프셋 커밋:** `poll()`로 읽은 마지막 오프셋이 아닌, '성공적으로 처리한 마지막 메시지의 다음 오프셋'을 커밋해야 함. 실수로 처리하지 않은 메시지의 오프셋을 커밋하면 데이터 유실로 이어짐.
- **리밸런스 처리:** 컨슈머 리밸런스가 발생할 것을 대비해야 함. 파티션 소유권을 잃기 전에 현재까지 처리한 오프셋을 커밋하고, 애플리케이션이 유지하던 상태(state)를 정리하는 로직이 필요함.
<br>

### (4) 고급 컨슈머 처리 패턴
- **재시도가 필요한 경우:**
    - 특정 메시지 처리 실패 시(예: DB 일시적 장애), 해당 메시지를 건너뛰고 다음 메시지의 오프셋을 커밋하면 안 됨.
    - **패턴 1 (Pause and Retry):** 성공한 마지막 오프셋까지 커밋하고, 실패한 메시지들은 별도 버퍼에 보관. 컨슈머의 `pause()` 메서드를 호출해 새 메시지 수신을 막고, 버퍼의 메시지를 재처리 시도.
    - **패턴 2 (Dead-Letter Queue):** 처리 실패한 메시지를 별도의 '재처리 토픽(retry topic)' 또는 '데드-레터 큐(dead-letter queue)'로 보냄. 별도의 컨슈머 그룹이 이 토픽을 구독하여 재처리를 담당.
- **상태 유지가 필요한 경우:**
    - 이동 평균 계산 등 여러 `poll()` 호출에 걸쳐 상태를 유지해야 하는 경우, 오프셋뿐만 아니라 애플리케이션의 상태도 함께 복구해야 함.
    - **패턴:** 오프셋을 커밋하는 시점에, 계산된 상태 값(예: 현재까지의 평균)을 별도의 토픽에 함께 기록. 컨슈머 재시작 시, 마지막으로 저장된 상태 값과 오프셋을 함께 읽어 작업을 재개.
    - **권장 사항:** 이런 복잡한 상태 기반 처리는 직접 구현하기보다 Kafka Streams, Flink와 같은 스트림 처리 프레임워크를 사용하는 것이 안정적이고 효율적임.
<br><br><br>





# 7.6 시스템 신뢰성 검증
<br>

### (1) 설정 검증
- **목적:**
    - 선택한 브로커 및 클라이언트 설정이 신뢰성 요구사항을 충족하는지 테스트.
    - 시스템의 예상 동작을 미리 파악하고 이해하기 위한 연습.
- **검증 도구:**
    - 카프카는 `org.apache.kafka.tools` 패키지 내에 검증용 도구를 포함.
    - **`VerifiableProducer`:** 1부터 지정된 숫자까지 순차적인 메시지를 생성. `acks`, `retries` 등 실제 프로듀서와 동일하게 설정 가능하며 각 메시지의 전송 성공/실패를 출력.
    - **`VerifiableConsumer`:** `VerifiableProducer`가 보낸 메시지를 소비하여 순서대로 출력. 오프셋 커밋 및 리밸런스 정보도 함께 출력.
- **주요 테스트 시나리오:**
    - **리더 선출:** 특정 파티션의 리더 브로커를 중단시켰을 때, 프로듀서와 컨슈머가 정상화되기까지 걸리는 시간 측정.
    - **컨트롤러 선출:** 컨트롤러 브로커를 재시작했을 때, 시스템이 정상화되는 시간 측정.
    - **롤링 리스타트:** 브로커를 하나씩 재시작하는 동안 메시지 유실이 없는지 확인.
    - **정결하지 못한 리더 선출 테스트:** 파티션의 모든 복제본을 순서대로 중단시켜 Out-of-Sync 상태로 만든 후, Out-of-Sync 상태였던 브로커를 재시작했을 때 어떤 현상이 발생하는지 확인.
<br>

### (2) 애플리케이션 검증
- **목적:** 브로커/클라이언트 설정 검증 후, 애플리케이션 로직(오류 처리, 오프셋 커밋, 리밸런스 리스너 등)이 의도한 대로 동작하는지 확인.
- **검증 방법:** 다양한 장애 상황을 주입하는 통합 테스트(Integration Test) 수행.
- **주요 장애 주입 시나리오:**
    - 클라이언트와 특정 브로커 간 네트워크 연결 끊김.
    - 클라이언트와 브로커 간 높은 지연 시간(high latency) 발생.
    - 디스크 꽉 참 (Disk full).
    - 디스크 응답 없음 (Hanging disk).
    - 리더 선출.
    - 브로커, 컨슈머, 프로듀서 각각 롤링 리스타트.
- **장애 주입 도구:**
    - 다양한 네트워크/디스크 장애 주입 도구 사용 가능.
    - 카프카 자체적으로 `Trogdor`라는 테스트 프레임워크를 포함.
<br>

### (3) 운영 환경에서의 신뢰성 모니터링
- **목적:** 테스트만으로는 부족하며, 실제 운영 환경에서 데이터 흐름이 예상대로 유지되는지 지속적으로 모니터링해야 함.
- **모니터링 영역:**
    - **프로듀서 모니터링:**
        - **주요 JMX 메트릭:** `error-rate`(오류율), `retry-rate`(재시도율). 이 수치가 증가하면 시스템 문제의 신호일 수 있음.
        - **로그 모니터링:** `WARN` 레벨의 재시도 로그, 특히 "0 attempts left"(재시도 소진) 로그 확인. `ERROR` 레벨 로그는 메시지 전송이 완전히 실패했음을 의미.
    - **컨슈머 모니터링:**
        - **가장 중요한 메트릭:** `consumer lag` (컨슈머가 최신 메시지로부터 얼마나 뒤처져 있는지를 나타냄).
        - 랙(lag)은 약간의 변동이 정상이지만, 지속적으로 증가하는 것은 문제.
        - `Burrow` (by LinkedIn)와 같은 도구를 사용하면 랙 모니터링 및 알림 설정이 용이함.
    - **종단 간(End-to-End) 데이터 흐름 모니터링:**
        - 모든 생성된 데이터가 비즈니스 요구사항에 맞는 시간 내에 소비되는지 확인.
        - 메시지 타임스탬프를 활용하여 '생성 시간'과 '소비 시간' 간의 지연 시간을 측정.
        - 프로듀서의 초당 생성 메시지 수와 컨슈머의 초당 소비 메시지 수를 비교하여 유실 여부 확인.
        - Confluent Control Center 등 상용 솔루션이 이러한 기능을 제공.
    - **브로커 모니터링 (오류 메트릭):**
        - **주요 메트릭:** `FailedProduceRequestsPerSec`, `FailedFetchRequestsPerSec`.
        - 롤링 리스타트 중 발생하는 `NOT_LEADER_FOR_PARTITION` 오류처럼 일부 오류는 정상적인 상황에서도 발생 가능.
        - 설명되지 않는 오류율 증가는 반드시 원인을 조사해야 함.
<br><br><br>
