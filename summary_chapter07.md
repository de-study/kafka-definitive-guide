# 7장: 신뢰성 있는 데이터 전송
<br><br>


## 1. Introduction: 신뢰성의 본질과 접근법

### (1) 신뢰성의 본질

* **핵심**: 신뢰성은 단일 컴포넌트가 아닌 **전체 시스템의 속성**임.
* **범위**: Kafka 클러스터뿐만 아니라, 연동되는 모든 시스템(Producer, Consumer, 인프라 등)이 신뢰성에 영향을 미침.
* **책임**: 카프카 관리자, 리눅스 관리자, 네트워크/스토리지 관리자, 애플리케이션 개발자 모두의 공동 책임임.

> **🚀 실리콘밸리 데이터 엔지니어의 독백:**
> "Meta에서 배운 건 '장애는 항상 경계선에서 발생한다'는 것임. 카프카와 다른 시스템 사이의 연결점을 항상 주의 깊게 봐야 함. 장애는 카프카 *안*에서보다 카프카*와* 앱 *사이*에서 훨씬 더 자주 발생함."
<br>

### (2) Kafka의 유연성과 위험성

* **특징**: Kafka는 매우 유연하여 다양한 신뢰성 요구사항을 충족시킬 수 있음.
* **위험성**: 유연성 때문에 잘못 설정할 경우, 신뢰성이 보장되지 않는데도 보장된다고 착각하기 쉬움.
* **트레이드오프**: 속도/단순성 vs. 신뢰성 사이에서 사용 사례에 맞는 선택이 필수적임.
    * **예시**: 웹사이트 클릭 추적(속도 우선) vs. 신용카드 결제(신뢰성 우선).

> **🚀 실리콘밸리 데이터 엔지니어의 독백:**
> "카프카 설정 파일을 보면서 '설정이 왜 이렇게 많아?' 했던 기억이 남. 카프카가 강력한 이유는 유연성인데, 이게 동시에 가장 위험한 부분이기도 함. 각 설정이 어떤 트레이드오프를 만드는지 이해하는 것이 엔지니어의 핵심 역량임."

---
<br><br><br>




## 2. 신뢰성 보장 (Reliability Guarantees)

### (1) Kafka의 핵심 보장 사항

* **필요성**: 관계형 DB의 ACID처럼, 시스템이 어떤 상황에서 어떻게 동작할지 예측 가능해야 신뢰하고 사용할 수 있음.

> **🚀 실리콘밸리 데이터 엔지니어의 독백:**
> "Goldman Sachs 트레이딩 시스템 마이그레이션할 때, 기존 Oracle DB의 ACID 보장에 익숙한 팀원들이 카프카의 '다른' 보장 방식을 이해하는 데 3주나 걸렸음. 이 차이를 이해하는 것이 첫걸음임."

* **보장 1: 파티션 내 순서 보장 (Order Guarantee)**
    * **정의**: 동일 프로듀서가 동일 파티션에 보낸 메시지 B가 메시지 A 이후에 전송되었다면, 오프셋은 항상 B > A이며, 컨슈머는 항상 A를 먼저 읽음.
    * **실무 팁**: 순서가 중요한 데이터(예: 은행 계좌 입출금, 주문 처리)는 반드시 **동일한 메시지 키(key)**로 전송해야 함. Kafka는 키의 해시값을 기반으로 파티션을 결정하기 때문.
        ```python
        # 같은 파티션으로 보내면 순서 보장됨
        producer.send('user-events', key='user123', value=event_a)  # offset: 100
        producer.send('user-events', key='user123', value=event_b)  # offset: 101
        # event_b는 항상 event_a 다음에 읽힘
        ```

* **보장 2: 커밋된 메시지 정의 (Committed Message)**
    * **정의**: 프로듀서가 보낸 메시지가 파티션의 **모든 ISR(In-Sync Replicas)**에 쓰였을 때 "커밋(committed)"된 것으로 간주됨.
    * **주의사항**: 디스크에 물리적으로 `flush` 되는 것과는 다른 개념. ISR들의 메모리에만 쓰여도 커밋으로 간주될 수 있음.
    * **실무적 의미**: "커밋됐다"는 것은 "브로커 하나가 죽어도 데이터는 안전하다"는 보장을 의미함.

* **보장 3: 프로듀서 ACK 레벨 선택 (Producer Acknowledgement)**
    * **정의**: 프로듀서는 메시지 전송 성공 여부를 언제 확인할지 선택 가능.
    * **레벨**:
        * `acks=0` (Fire-and-forget): 전송 요청만 하고 확인 안 함. 속도 최고, 유실 위험 최대.
        * `acks=1` (Leader only): 리더에만 쓰이면 성공. 속도와 신뢰성 절충. 리더 장애 시 유실 가능.
        * `acks=all` (All ISRs): 모든 ISR에 쓰여야 성공. 신뢰성 최고, 속도 저하.
> **🚀 실리콘밸리 데이터 엔지니어의 독백:**
> "JPMorgan Chase에서 거래 데이터 처리 시 `acks=all` 설정으로 평균 지연시간이 200ms 늘어났지만, 연간 수십억 달러 거래에서 데이터 손실 리스크를 0에 가깝게 만들었으므로 충분히 가치 있는 선택이었음."

* **보장 4: 컨슈머는 커밋된 메시지만 읽음 (Read Committed)**
    * **정의**: 컨슈머는 오직 "커밋된" 상태의 메시지만 읽을 수 있음.
    * **실무적 의미**: 데이터 일관성 보장의 핵심. 만약 커밋되지 않은 메시지를 읽을 수 있다면, 컨슈머가 처리한 데이터가 브로커 장애로 사라지는 유령 데이터(ghost data)가 될 수 있음. 카프카는 이를 원천적으로 방지함.

* **통합 예시: 전자상거래 주문 처리 시스템**
    * **순서 보장**: '장바구니 추가 → 결제 진행 → 재고 차감' 이벤트가 같은 `key`로 전송되어 순서대로 처리됨.
    * **Committed 보장**: '결제 완료' 이벤트가 `committed` 상태가 되어야 배송팀 컨슈머가 읽을 수 있음. 브로커가 죽어도 결제 기록은 안전함.
    * **ACK 레벨**: 결제 시스템은 `acks=all`을 사용하여, 고객에게 '결제 완료' 응답을 보내기 전에 데이터가 안전하게 저장되었음을 보장함.
    * **Read Committed**: 배송팀 컨슈머는 `committed`된 주문만 읽으므로, '존재하지 않는 주문'을 처리할 위험이 없음.
<br>


### (2) 컨슈머 오프셋 커밋 (Consumer Offset Commit)

* **정의**: 컨슈머가 "나는 이 파티션의 여기까지 읽고 처리했다"고 카프카에 체크포인트를 남기는 행위.
* **필요성**: 컨슈머 장애 후 재시작하거나, 다른 컨슈머가 작업을 이어받을 때 중복 처리나 데이터 누락을 방지하기 위함.
* **`enable.auto.commit` (자동 커밋)**:
    * **정의**: `auto.commit.interval.ms` 주기로 컨슈머가 자동으로 오프셋을 커밋하는 기능.
    * **위험성**: 메시지 처리가 완료되기 전에 오프셋이 먼저 커밋될 수 있음. 이 상태에서 앱이 다운되면 해당 메시지는 처리되지 않고 영원히 누락됨.
    * **설정 방법**:
        ```java
        // Java Consumer Properties
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "my-group");
        props.put("enable.auto.commit", "true"); // 자동 커밋 활성화
        props.put("auto.commit.interval.ms", "1000"); // 1초마다 커밋
        ```
---
<br><br><br>



## 3. 신뢰성 설계를 위한 의사결정 프레임워크

> **🚀 실리콘밸리 데이터 엔지니어의 독백:**
> "최고의 설정을 묻는 질문에 대한 나의 대답은 항상 '경우에 따라 다르다(It depends)'임. 당신의 가치는 '최고의 설정'을 아는 것이 아니라, '최고의 질문'을 던질 줄 아는 것에 있음. 지금부터 그 질문들을 알려주겠음."

### (1) Step 1: 비즈니스 요구사항 분석 (Ask the Right Questions)

* **목표**: 기술적 설정을 하기 전, 비즈니스의 맥락을 완벽히 이해하는 단계.
* **핵심 질문 리스트**:
    * **데이터 중요도 (Data Criticality)**: 이 데이터가 유실되면 회사가 직접적인 금전적 손실을 보는가? (예: 결제, 주문)
    * **서비스 수준 협약 (SLA)**: 장애 시 최대 얼마만큼의 데이터 손실(RPO)과 복구 시간(RTO)을 감수할 수 있는가?
    * **성능 요구사항**: 최대 처리량(Throughput)과 최소 지연 시간(Latency) 요구사항은 무엇인가?
    * **비용 제약**: 할당된 인프라 비용(서버, 스토리지, 네트워크)은 얼마인가?
<br>


### (2) Step 2: 상황별 설정 템플릿 적용 (Choose Your Weapon)

* **목표**: 1단계 분석 결과를 바탕으로, 가장 적합한 설정 조합의 기준점을 선택.

| 구분 | **A. 최대 신뢰성 (Maximum Reliability)** | **B. 균형 (Balanced)** | **C. 성능 우선 (Performance First)** |
| :--- | :--- | :--- | :--- |
| **사용 사례** | 결제, 주문, 금융 거래 시스템 | 핵심 비즈니스 이벤트, 사용자 정보 변경 | 대용량 로그 수집, IoT 센서 데이터, 모니터링 메트릭 |
| **목표** | **데이터 무손실(Zero Data Loss)**, **정합성** | 높은 신뢰성과 준수한 성능의 균형 | **최대 처리량(High Throughput)**, **저지연(Low Latency)** |
| **브로커 설정** | `replication.factor=3`<br>`min.insync.replicas=2`<br>`unclean...=false` | `replication.factor=3`<br>`min.insync.replicas=2`<br>`unclean...=false` | `replication.factor=2 or 3`<br>`min.insync.replicas=1`<br>`unclean...=false` |
| **프로듀서 설정**| `acks=all`<br>`enable.idempotence=true`<br>`delivery.timeout.ms=120000` | `acks=all`<br>`enable.idempotence=true`<br>`linger.ms=5` (성능 튜닝) | `acks=1`<br>`linger.ms=20`<br>`batch.size=65536`<br>`compression.type=lz4` |
| **컨슈머 설정** | `enable.auto.commit=false`<br>`auto.offset.reset=earliest`<br>(수동 커밋) | `enable.auto.commit=false`<br>`auto.offset.reset=earliest`<br>(수동 커밋) | `enable.auto.commit=true`<br>`auto.commit.interval.ms=500`<br>`auto.offset.reset=latest` |
| **감수하는 것** | 처리량 및 지연 시간의 약간의 손해 | - (대부분의 서비스에 대한 표준) | 장애 시 **데이터 유실** 및 **중복** 가능성 |
> **🚀 실리콘밸리 데이터 엔지니어의 독백:**
> "auto commit은 데이터 손실의 지름길임. 신뢰성이 조금이라도 중요하다면 무조건 false로 설정하고, 처리가 완벽히 끝난 후 수동으로 커밋해야 함."
> `consumer.commitSync(); // 성공 시에만 명시적으로 커밋`


---
<br><br><br>







## 4. 설정 상세 가이드: 트레이드오프의 이해

### (1) 브로커 설정

#### `replication.factor` (복제 계수)

* **의미**: 데이터를 몇 개의 복제본으로 저장할지 결정하는 값.
* **실무적 영향**: `replication.factor=N`은 N-1개의 브로커 장애를 견딜 수 있음을 의미. 데이터의 생존 가능성을 직접 결정하는 가장 기본적인 설정.
* **설정 방법**: 토픽 생성 시 지정 (권장).
    ```bash
    bin/kafka-topics.sh --create --topic critical-orders --bootstrap-server kafka1:9092 --replication-factor 3 --partitions 12
    ```
> **🚀 실리콘밸리 데이터 엔지니어의 독백:**
> "프로덕션 환경에서 `replication.factor=1`은 논외임. 최소 3으로 시작하고, `broker.rack` 설정을 통해 여러 가용 영역(AZ)에 분산 배치하는 것이 표준임."

#### `unclean.leader.election.enable` (불완전한 리더 선출)

* **의미**: ISR에 아무도 없을 때, 데이터가 뒤처진(out-of-sync) 복제본을 리더로 선출할지 여부.
* **실무적 영향**: `true`로 설정 시, **가용성**을 얻는 대신 **데이터 정합성을 포기**하는 것. 즉, 데이터 유실을 감수하겠다는 의미.
* **설정 방법**: 브로커의 `config/server.properties` 파일.
    ```properties
    # config/server.properties
    unclean.leader.election.enable = false
    ```
> **🚀 실리콘밸리 데이터 엔지니어의 독백:**
> "`false`로 두고 잊어버리는 게 좋음. 데이터 유실은 엔지니어가 책임질 수 있는 문제가 아님. 비즈니스 리더의 명시적인 동의 없이는 절대 `true`로 바꾸지 말 것."

#### `min.insync.replicas` (최소 동기화 복제본 수)

* **의미**: 프로듀서(`acks=all` 설정 시)의 쓰기 요청이 성공으로 간주되기 위해 필요한 최소 ISR 개수.
* **실무적 영향**: 데이터 내구성을 위한 최후의 방어선. 예를 들어 `min.insync.replicas=2`로 설정 시, ISR이 1개로 줄면 쓰기 요청이 실패하여 최소 2곳에 데이터가 저장됨을 보장함.
* **설정 방법**: 토픽별 설정 (권장).
    ```bash
    bin/kafka-configs.sh --bootstrap-server kafka1:9092 --alter --entity-type topics --entity-name critical-orders --add-config min.insync.replicas=2
    ```
> **🚀 실리콘밸리 데이터 엔지니어의 독백:**
> "`acks=all`과 `min.insync.replicas`는 한 세트임. `acks=all`만 믿고 있다가 ISR이 1개만 남으면 `acks=1`처럼 동작하게 됨. 이 설정을 통해 '어떤 상황에서도 최소 두 군데에는 저장돼야 한다'는 강력한 규칙을 만들어야 함."
<br>


### (2) 프로듀서/컨슈머 설정

#### 프로듀서: 신뢰성의 황금 설정 (Golden Configuration)

* **핵심**: `acks=all`, `enable.idempotence=true`, `delivery.timeout.ms` 3종 세트.
* **실무적 영향**: 데이터 유실, 중복, 순서 깨짐 문제를 대부분 예방함.
* **설정 방법** (애플리케이션 코드):
    ```java
    // Java Producer Properties
    Properties props = new Properties();
    props.put("bootstrap.servers", "kafka1:9092,kafka2:9092");
    
    props.put("acks", "all"); // 모든 ISR의 확인을 받음
    props.put("enable.idempotence", "true"); // 멱등성을 활성화하여 중복 방지
    props.put("delivery.timeout.ms", 120000); // 2분 내 재시도 포함 전송 보장
    ```

#### 컨슈머: 신뢰성의 마침표

* **핵심**: 오프셋 커밋을 수동으로 제어하여 '처리 완료'를 보장.
* **실무적 영향**: `enable.auto.commit=true`는 편리하지만, 메시지 처리 실패 또는 앱 다운 시 데이터 처리 누락 또는 중복을 유발할 수 있음.
* **설정 방법** (애플리케이션 코드):
    ```java
    // Java Consumer Properties
    Properties props = new Properties();
    props.put("bootstrap.servers", "kafka1:9092,kafka2:9092");
    props.put("group.id", "order-processor");
    
    props.put("enable.auto.commit", "false"); // 수동 커밋
    props.put("auto.offset.reset", "earliest"); // 유실 방지
    
    // 애플리케이션 로직 내에서 처리 완료 후 명시적으로 커밋
    // consumer.commitSync();
    ```
---
<br><br><br>







## 5. 복제(Replication) 상세 및 최신 업데이트

### (1) 기본 구조 및 동작

* **파티션**: 토픽을 나누는 기본 단위. 파티션 단위로 복제 및 순서 보장.
* **리더-팔로워 구조**:
    * 각 파티션은 하나의 리더와 여러 팔로워를 가짐.
    * 모든 읽기/쓰기는 리더를 통해 이루어져 데이터 일관성을 보장함.
    * 리더 장애 시, ISR 중에서 새로운 리더가 자동으로 선출됨.
* **동기화 상태 관리 (ISR)**:
    * 팔로워가 리더의 최신 데이터를 일정 시간 내에 따라잡아야 ISR 멤버로 유지됨.
    * ISR 멤버 수 감소는 클러스터의 건강 상태 악화를 의미하는 중요한 모니터링 지표임.
<br>


### (2) 최신 업데이트 (Kafka 4.0 / 2025년 기준)

* **ZooKeeper 완전 제거**: KRaft가 기본 메타데이터 관리 방식으로 단일화되어 운영 복잡성이 대폭 감소함.
* **Java 버전 요구사항 변경**: 브로커는 Java 17+, 클라이언트는 Java 11+ 필수.
* **컨슈머 리밸런스 프로토콜 개선**: "stop-the-world" 리밸런스가 사라지고 점진적 할당 방식으로 변경되어 서비스 중단 시간 감소.

---
<br><br><br>





## 6. 최종 단계: 신뢰성 검증

> **🚀 실리콘밸리 데이터 엔지니어의 독백:**
> "시니어 엔지니어는 아무것도 믿지 않음. 자기가 짠 코드도, 자기가 한 설정도. 그래서 계속 부숴보려고 함. 프로덕션에서 장애로 터지기 전에, 스테이징에서 먼저 터트려보는 것. 이게 당신을 살려줄 것임."

### (1) 왜 필요한가?

* **이론과 현실의 간극**: 설정값이 실제 장애 상황에서 이론대로 동작하는지 증명.
* **가장 약한 고리 발견**: 시스템의 신뢰성은 가장 취약한 부분(대부분 직접 짠 코드)에 의해 결정됨.
* **"조용한 실패(Silent Failure)" 방지**: 겉으로 정상처럼 보여도 내부적으로 문제가 발생하는 것을 사전에 감지.
<br>


### (2) 검증 방법

| 검증 단계 | 무엇을 검증하는가? (What) | 어떻게 검증하는가? (How) | 안 하면 어떻게 되는가? (Consequences) |
| :--- | :--- | :--- | :--- |
| **레이어 1: 설정 검증** | 카프카 자체의 설정값(복제, 리더 선거 등)이 장애 상황에서 의도대로 동작하는지 확인. | - **도구**: `kafka-verifiable-producer`, `kafka-verifiable-consumer` 사용.<br>- **시나리오**: 브로커 강제 종료(`kill -9`), 롤링 재시작 등을 수행하며 데이터 유실 여부와 복구 시간 측정. | "고가용성 설정이라 믿었지만, 실제로는 브로커 재시작 시 30초간 서비스가 다운되고 일부 트랜잭션이 실패함." |
| **레이어 2: 애플리케이션 검증** | 직접 작성한 애플리케이션 코드(에러 처리, 오프셋 커밋 등)가 장애 상황을 견디는지 확인. | - **방법**: **장애 주입(Fault Injection)**. <br>- **시나리오**: 네트워크 단절/지연, 디스크 Full, DB 등 의존성 서비스 강제 종료 등을 시뮬레이션하며 애플리케이션의 반응을 테스트. | "DB 장애 시 컨슈머가 오프셋 커밋을 잘못 처리하여, **수천 건의 주문 데이터가 영원히 유실**되는 대형 장애 발생." |
| **레이어 3: 운영 환경 모니터링** | 실제 운영 환경에서 시스템이 안정적으로 동작하며, 이상 징후를 즉시 감지할 수 있는지 확인. | - **지표**: `Consumer Lag`, `Producer Error/Retry Rate`, `End-to-End Latency` 등 핵심 지표 모니터링.<br>- **구축**: Prometheus/Grafana 등으로 대시보드 및 알람(Alerting) 시스템 구축. | "Consumer Lag이 몇 주간 서서히 쌓이는 것을 아무도 몰랐고, 결국 데이터가 **며칠이나 지연**되어 비즈니스 SLA를 위반하고 고객 신뢰를 잃음." |


---
<br><br><br>







## 7. 최종 결론: 데이터 엔지니어의 역할과 실무 팁

### (1) 데이터 엔지니어의 역할

* **데이터 엔지니어는 단순히 파이프라인을 구축하는 사람이 아님.**
* **역할**:
    * **비즈니스와 기술의 번역가**: 비즈니스의 요구사항을 기술적인 설정값으로 변환하고, 그 기술적 선택이 비즈니스에 미칠 영향을 설명함.
    * **리스크 관리자**: 데이터 유실, 서비스 중단 등의 리스크를 식별하고, 설정을 통해 그 리스크를 허용 가능한 수준으로 관리함.
    * **시스템 설계자**: 특정 상황에 맞는 최적의 신뢰성 모델을 설계하고, 그 설계를 테스트를 통해 증명하며, 지속적으로 개선함.

> **🚀 실리콘밸리 데이터 엔지니어의 독백:**
> "결국 우리의 일은 '가장 좋은' 설정을 찾는 것이 아니라, 주어진 비즈니스 제약 조건 하에서 '가장 적절한' 설정을 찾아내고 그 선택을 데이터로 증명하는 것임. 완벽한 시스템은 없음. 오직 트레이드오프를 잘 이해하고 관리하는 훌륭한 엔지니어만 있을 뿐임."
<br>


### (2) 실무 최종 꿀팁 (Rules of Thumb)

* **항상 3개 브로커로 시작**: "브로커 1~2개는 장난감임."
* **`acks=all`을 기본값으로**: "성능 최적화는 나중에, 안정성부터 확보할 것."
* **수동 커밋 사용**: "`auto.commit`은 데이터 손실의 지름길."
* **모니터링 먼저 구축**: "측정할 수 없으면, 개선할 수 없음. 장애는 새벽에 옴."
* **카오스 엔지니어링 도입**: "가장 친한 친구는 스테이징 환경에서 내 시스템을 계속해서 부숴주는 스크립트임."
<br>
