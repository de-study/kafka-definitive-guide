# Chapter 8. Kafka 정확히 한 번 의미 구조 (Exactly-Once Semantics) 

## 1. 개요
- **배경**: 
	- Kafka의 기본 보장 수준인 **'적어도 한 번 전달(at-least-once delivery)'**은 메시지 유실은 없으나 중복이 발생할 수 있는 가능성 내포.
- **문제점**: 
	- 단순 메시지 소비 환경에서는 중복 처리가 용이하나, 집계(aggregation)와 같은 스트림 처리 애플리케이션에서는 중복된 이벤트 처리가 결과의 정확성을 심각하게 훼손 가능
- **목표**:  
	- **'정확히 한 번 처리(exactly-once processing)'** 의미론을 달성하기 위한 Kafka의 두 가지 핵심 기능, **멱등성 프로듀서(Idempotent Producer)**와 **트랜잭션(Transactions)**에 대해 상세히 기술
---

## 2. 멱등적 프로듀서 (Idempotent Producer)
- **정의**: 
	- 동일한 작업을 여러 번 수행해도 단 한 번 수행한 것과 같은 결과를 보장하는 **멱등성(Idempotence)** 원리를 프로듀서에 적용한 기능. 
	- 프로듀서의 내부 재시도 로직으로 인해 발생할 수 있는 메시지 중복을 방지.
### 2.1. 핵심 메커니즘
- **고유 식별자**:
    - 멱등성이 활성화되면 모든 메시지에 고유한 **프로듀서 ID(PID)**와 0부터 순차적으로 증가하는 **시퀀스 번호** 포함
    - PID, 시퀀스 번호, 토픽-파티션 정보를 조합하여 각 메시지를 고유하게 식별.        
- **중복 감지**:
    - 브로커는 각 파티션별로 최근 5개의 PID와 시퀀스 번호 조합을 메모리에 추적.
    - 이미 수신한 시퀀스 번호의 메시지를 다시 받으면, 브로커는 이를 중복으로 간주하고 오류와 함께 거부.
	    - 이 오류는 프로듀서에게 예외를 발생시키지 않으며 정상적인 동작으로 간주.
### 2.2. 장애 시나리오별 동작
- **프로듀서 재시작**:
    - 프로듀서 애플리케이션이 재시작되면 완전히 새로운 PID 발급.
    - 따라서 이전 인스턴스가 보냈던 메시지를 새 인스턴스가 재전송하더라도 PID가 달라 중복으로 간주되지 않음.        
- **브로커 장애**:
    - 팔로워 리플리카는 리더로부터 데이터를 복제할 때 프로듀서 상태(PID, 시퀀스 번호)도 함께 복제하여 메모리에 유지.
    - 따라서 팔로워가 새로운 리더가 되어도 중복 방지 메커니즘이 끊김 없이 동작.
    - 브로커 재시작 시에는 셧다운 시 저장한 스냅샷이나 로그의 마지막 세그먼트를 읽어 프로듀서 상태를 복구.
### 2.3. 제한 사항
- 멱등성 프로듀서는 프로듀서의 **내부 재시도 로직 으로 인한 중복만 방지**
	- 애플리케이션 코드 레벨에서 `producer.send()`를 두 번 호출하거나, 서로 다른 프로듀서 인스턴스가 같은 메시지를 보내는 경우는 막을 수 없음.
### 2.4. 구성 방법
- 프로듀서 설정에 `enable.idempotence=true`를 추가하여 활성화.
- 이 설정은 `acks=all`과 같은 높은 안정성을 보장하는 다른 설정들도 자동으로 활성화하며, 성능 저하는 거의 없음.
---

## 3. 트랜잭션 (Transactions)
- **정의**: Kafka Streams와 같은 스트림 처리 애플리케이션에서 **"소비-처리-생산(Consume-Process-Produce)"** 패턴의 모든 단계를 하나의 원자적 단위로 묶어 종단 간(end-to-end) 정확히 한 번 처리를 보장하는 기능.
### 3.1. 해결 과제
1. **애플리케이션 충돌로 인한 재처리**: 
	- 메시지를 처리하여 결과를 생산한 직후, 입력 메시지의 오프셋을 커밋하기 전에 애플리케이션이 다운되면, 재시작 시 동일 메시지를 다시 처리하여 결과가 중복되는 문제.
2. **좀비 인스턴스 (Zombie Instances)**: 
	- 네트워크 단절 등으로 소비자 그룹에서 제외된 인스턴스(좀비)가 뒤늦게 되살아나 이미 처리된 데이터를 다시 생산하여 중복을 유발하는 문제.
### 3.2. 핵심 메커니즘
- **원자적 다중 파티션 쓰기:**
    - **(A) 결과 메시지를 출력 토픽에 쓰는 작업**과 **(B) 입력 메시지의 오프셋을 `__consumer_offsets` 토픽에 커밋하는 작업**을 하나의 원자적 트랜잭션으로 묶는 것이 트랜잭션의 핵심.    
    - 그림 8-1. 트랜잭션적 프로듀서와 여러 파티션에 대한 원자적 쓰기
		![그림 8-1. 트랜잭션적 프로듀서와 여러 파티션에 대한 원자적 쓰기](https://i.imgur.com/MwDi326.png)
- **트랜잭션적 프로듀서 사용**:
	- `transactional.id`:
	    - 재시작 시에도 유지되는 고유 ID로, 프로듀서를 식별하는 데 사용.
	- `initTransactions()`를 호출하여 초기화
- **좀비 펜싱 (Zombie Fencing)**:
    - 브로커는 `transactional.id`와 함께 **에포크(epoch)** 번호를 관리함.
    - 새로운 프로듀서 인스턴스가 초기화되면 에포크가 증가하며, 브로커는 이전(낮은) 에포크를 가진 좀비 프로듀서의 요청을 거부하여 잘못된 쓰기를 원천 차단.
### 3.3 트랜잭션 작동 원리
#### 트랜잭션 작동 원리 상세: 생명주기
- **기반 알고리즘**: 
	- Kafka 트랜잭션은 **2단계 커밋(Two-Phase Commit)** 프로토콜과 **트랜잭션 로그(`_transaction_state` 토픽)**를 사용하여 원자성을 보장.
- **핵심 구성요소**:
    - **트랜잭션 코디네이터 (Transaction Coordinator)**: 각 프로듀서의 트랜잭션 상태를 관리하고 과정을 조율하는 브로커 컴포넌트.
##### 1단계: 초기화 (`initTransactions()`)
- **목적**: 프로듀서를 트랜잭셔널 프로듀서로 등록.
- **프로세스**:
    1. 프로듀서는 **트랜잭션 코디네이터**에게 `initTransaction()` 요청을 전송.        
    2. 코디네이터는 해당 `transactional.id`를 등록하고 **에포크(epoch) 번호를 증가**시킴.
    3. **좀비 펜싱**: 증가된 에포크는 이전 세대의 프로듀서(좀비)를 식별하고 차단하는 데 사용됨.
    4. 이전 에포크에서 완료되지 않은 모든 진행 중인 트랜잭션은 자동으로 중단(abort)됨.
##### 2단계: 트랜잭션 시작 (`beginTransaction()`)
- **목적**: 실제 데이터 처리를 위한 트랜잭션 범위 설정.
- **프로세스**:
    - 이 API 호출은 프로토콜 요청 없이, **프로듀서 클라이언트 내부의 상태**를 '트랜잭션 진행 중'으로 변경.
##### 3단계: 파티션 등록 및 데이터 전송 (`send()`)
- **목적**: 트랜잭션 범위 내에서 데이터를 처리하고 결과 메시지를 파티션에 전송.
- **프로세스**:
    1. 프로듀서가 특정 파티션에 **처음으로** 메시지를 보낼 때, `AddPartitionsToTxnRequest` 요청이 코디네이터에게 함께 전송.
    2. 코디네이터는 해당 파티션이 현재 트랜잭션에 포함되었음을 **트랜잭션 로그에 기록**.
##### 4단계: 오프셋 커밋 (`sendOffsetsToTransaction()`)
- **목적**: 소비한 입력 메시지의 오프셋을 현재 트랜잭션에 원자적으로 포함.
- **프로세스**:
    - 프로듀서는 처리한 오프셋 정보와 컨슈머 그룹 ID를 코디네이터에게 전송. 
    - 코디네이터는 이를 해당 그룹 코디네이터를 통해 트랜잭션의 일부로 커밋.
##### 5단계: 최종 결정 - 2단계 커밋 (커밋 또는 중단)
- **목적**: 트랜잭션의 모든 작업을 최종적으로 확정하거나 모두 취소.
- **프로세스**:
    1. **1단계 (Prepare)**: 
	    - 프로듀서는 `EndTransactionRequest`를 코디네이터에게 전송. 
	    - 코디네이터는 **'커밋' 또는 '중단' 의도(intention)**를 트랜잭션 로그에 기록. 
		    - 이 로그가 기록되면 트랜잭션의 최종 결과는 확정됨.
    2. **2단계 (Commit/Abort)**:
        - 코디네이터는 트랜잭션에 포함된 **모든 파티션에 '커밋 마커' 또는 '중단 마커'를 기록**.
        - 모든 파티션에 마커 기록이 완료되면, 코디네이터는 최종적으로 트랜잭션 **완료 상태**를 트랜잭션 로그에 기록.
- **장애 복구**: 마커 기록 도중 코디네이터가 다운되면, 새로 선출된 코디네이터가 트랜잭션 로그를 읽고 중단되었던 작업을 재개하여 완료.
### 3.4. 관련 컴포넌트 구성
- **프로듀서**: `transactional.id`를 반드시 설정해야 함.
- **컨슈머**:
    - 트랜잭션으로 쓰인 데이터를 올바르게 읽기 위해 `isolation.level` 설정을 `read_committed`로 지정.
    - 이 설정은 성공적으로 커밋된 트랜잭션의 메시지만 읽도록 보장하며, 진행 중이거나 중단된(aborted) 트랜잭션의 메시지는 반환하지 않음.
    - 오프셋 자동 커밋은 비활성화(`enable.auto.commit=false`).
    - 그림 8-2. `read_committed` 모드로 작동 중인 컨슈머는 `read_uncommitted` 모드로 작동하는 컨슈머 (기본값) 보다 약간 더 뒤에 있는 메시지를 읽는다
	    ![그림 8-2](https://i.imgur.com/a5nhG22.png)
### 3.5. 보장 범위 및 제한 사항
- Kafka 트랜잭션의 보장 범위는 **Kafka 토픽에 대한 쓰기 작업에만 국한**.
- 다음과 같은 외부 시스템과의 상호작용은 트랜잭션 범위에 포함되지 않아 정확히 한 번을 보장할 수 없음:
    - 스트림 처리 중 이메일 발송, REST API 호출, 파일 시스템에 쓰기.
    - Kafka 토픽에서 데이터를 읽어 외부 데이터베이스에 쓰는 작업.
    - 이러한 문제는 **Outbox 패턴** 등을 사용하여 해결 가능.
### 3.6. 구현 방법
#### 권장 방식: Kafka Streams
- Kafka Streams 애플리케이션에서 `processing.guarantee` 설정을 `exactly_once` 또는 `exactly_once_beta`로 지정하는 것이 가장 쉽고 안정적인 방법. 
- Kafka Streams가 내부적으로 트랜잭션 API를 사용하여 모든 복잡성을 처리.
#### 직접 API를 사용한 트랜잭션 구현
- Kafka Streams를 사용하지 않을 경우, 프로듀서와 컨슈머의 트랜잭션 API를 직접 호출하여 구현 필요.
##### 1. 프로듀서 및 컨슈머 설정
- **프로듀서**:
    - `transactional.id`를 반드시 고유하고 영속적인 값으로 설정해야 함. 
    - 이 ID는 애플리케이션 인스턴스를 식별하는 기준.
- **컨슈머**:
    - `enable.auto.commit`을 `"false"`로 설정하여 오프셋 자동 커밋을 비활성화해야 함. 오프셋 커밋은 프로듀서가 트랜잭션 내에서 직접 처리
    - `isolation.level`을 `"read_committed"`로 설정하여 성공적으로 커밋된 트랜잭션의 메시지만 읽도록 보장 필요
##### 2. 트랜잭션 초기화
- `producer.initTransactions()`를 호출함.
- **역할**:
    - 브로커의 트랜잭션 코디네이터에 `transactional.id`를 등록함.
    - 에포크(epoch) 번호를 증가시켜 이전 세대의 좀비 프로듀서를 차단(fencing)할 준비.
    - 동일한 `transactional.id`로 이전에 진행 중이던 트랜잭션이 있었다면 모두 중단(abort)
##### 3. 메인 처리 루프 (`while(true)`)
- **3.1. 트랜잭션 시작**:
    - `producer.beginTransaction()`을 호출.
    - 이 시점은 프로듀서 클라이언트에게 트랜잭션이 시작되었음을 알리는 단계이며, 실제 트랜잭션 정보는 첫 메시지가 전송될 때 브로커로 전달.
- **3.2. 메시지 처리 및 전송**:
    - 컨슈머로부터 레코드를 폴링(poll)하여 가져온 후, 필요한 비즈니스 로직을 수행함.
    - 처리된 결과를 `producer.send()`를 통해 출력 토픽으로 전송함. 이 메시지들은 아직 커밋되지 않은 상태.
- **3.3. 오프셋을 트랜잭션에 포함**:
    - `producer.sendOffsetsToTransaction()`을 호출하여 소비한 메시지의 오프셋을 현재 트랜잭션에 포함.
    - **중요**: 
	    - 이 방식이 트랜잭션 환경에서 오프셋을 커밋하는 유일하게 안전한 방법. 
	    - 컨슈머의 `commitSync/Async` API를 호출하거나 자동 커밋을 사용하면 트랜잭션 보장이 깨짐.
- **3.4. 트랜잭션 커밋**:
    - `producer.commitTransaction()`을 호출
    - 이 호출이 성공적으로 반환되면, 전송했던 모든 메시지와 오프셋 커밋이 원자적으로 처리되어 외부 컨슈머에게 비로소 보이게 됨.
##### 4. 예외 처리
- **좀비 펜싱 예외 (`ProducerFencedException`)**:
    - 이 예외가 발생하면 현재 프로듀서 인스턴스가 좀비가 되었음을 의미.
    - 네트워크 단절 등의 이유로 새로운 인스턴스가 이미 작업을 시작한 상태이므로, 현재 인스턴스는 더 이상 작업을 진행하지 말고 정상적으로 종료해야 한다.
- **기타 Kafka 예외 (`KafkaException`)**:
    - 트랜잭션 도중 다른 오류가 발생하면 `catch` 블록으로 진입.
    - `producer.abortTransaction()`을 호출하여 진행 중이던 모든 작업을 롤백.
    - 컨슈머의 위치를 마지막으로 성공적으로 커밋된 오프셋으로 재설정하여, 실패한 배치를 다시 처리할 수 있도록 준비.
    