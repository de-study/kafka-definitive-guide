## Chapter 8. Kafka 정확히 한 번 의미 구조 (Exactly-Once Semantics) 

### **1. 개요**

- **배경**: Kafka의 기본 보장 수준인 **'적어도 한 번 전달(at-least-once delivery)'**은 메시지 유실은 없으나 중복이 발생할 수 있는 가능성을 내포.
    
- **문제점**: 단순 메시지 소비 환경에서는 중복 처리가 용이하나, 집계(aggregation)와 같은 스트림 처리 애플리케이션에서는 중복된 이벤트 처리가 결과의 정확성을 심각하게 훼손 가능
    
- **목표**:  **'정확히 한 번 처리(exactly-once processing)'** 의미론을 달성하기 위한 Kafka의 두 가지 핵심 기능, **멱등성 프로듀서(Idempotent Producer)**와 **트랜잭션(Transactions)**에 대해 상세히 기술하는 것이 목표
    

---

### **2. 멱등적 프로듀서 (Idempotent Producer)**

- **정의**: 
	- 동일한 작업을 여러 번 수행해도 단 한 번 수행한 것과 같은 결과를 보장하는 **멱등성(Idempotence)** 원리를 프로듀서에 적용한 기능. 
	- 프로듀서의 내부 재시도 로직으로 인해 발생할 수 있는 메시지 중복을 방지.
    

#### **2.1. 핵심 메커니즘**

- **고유 식별자**:
    
    - 멱등성이 활성화되면 모든 메시지에 고유한 **프로듀서 ID(PID)**와 0부터 순차적으로 증가하는 **시퀀스 번호** 포함
    - 이 두 값과 토픽-파티션 정보의 조합은 각 메시지를 고유하게 식별.
        
- **중복 감지**:
    
    - 브로커는 각 파티션별로 최근 5개의 PID와 시퀀스 번호 조합을 메모리에 추적.
    - 이미 수신한 시퀀스 번호의 메시지를 다시 받으면, 브로커는 이를 중복으로 간주하고 거부.
        

#### **2.2. 장애 시나리오별 동작**

- **프로듀서 재시작**:
    
    - 프로듀서 애플리케이션이 재시작되면 완전히 새로운 PID 발급.
        
    - 따라서 이전 인스턴스가 보냈던 메시지를 새 인스턴스가 재전송하더라도 PID가 달라 중복으로 간주되지 않음.
        
- **브로커 장애**:
    
    - 팔로워 리플리카는 리더로부터 데이터를 복제할 때 프로듀서 상태(PID, 시퀀스 번호)도 함께 복제하여 메모리에 유지.
        
    - 따라서 팔로워가 새로운 리더가 되어도 중복 방지 메커니즘이 끊김 없이 동작.
        
    - 브로커 재시작 시에는 셧다운 시 저장한 스냅샷이나 로그의 마지막 세그먼트를 읽어 프로듀서 상태를 복구.
        

#### **2.3. 제한 사항**

- 멱등성 프로듀서는 프로듀서의 **내부 재시도 로직 으로 인한 중복만 방지**
    
- 애플리케이션 코드 레벨에서 `producer.send()`를 두 번 호출하거나, 서로 다른 프로듀서 인스턴스가 같은 메시지를 보내는 경우는 막을 수 없음.
    

#### **2.4. 구성 방법**

- 프로듀서 설정에 `enable.idempotence=true`를 추가하여 활성화.
    
- 이 설정은 `acks=all`과 같은 높은 안정성을 보장하는 다른 설정들도 자동으로 활성화하며, 성능 저하는 거의 없음.
    

---

### **3. 트랜잭션 (Transactions)**

- **정의**: Kafka Streams와 같은 스트림 처리 애플리케이션에서 **"소비-처리-생산(Consume-Process-Produce)"** 패턴의 모든 단계를 하나의 원자적 단위로 묶어 종단 간(end-to-end) 정확히 한 번 처리를 보장하는 기능.
    

#### **3.1. 해결 과제**

1. **애플리케이션 충돌로 인한 재처리**: 메시지를 처리하여 결과를 생산한 직후, 입력 메시지의 오프셋을 커밋하기 전에 애플리케이션이 다운되면, 재시작 시 동일 메시지를 다시 처리하여 결과가 중복되는 문제.
    
2. **좀비 인스턴스 (Zombie Instances)**: 네트워크 단절 등으로 소비자 그룹에서 제외된 인스턴스가 뒤늦게 되살아나 이미 처리된 데이터를 다시 생산하여 중복을 유발하는 문제.
    

#### **3.2. 핵심 메커니즘**

- **원자적 다중 파티션 쓰기**:
    
    - **(A) 결과 메시지를 출력 토픽에 쓰는 작업**과 **(B) 입력 메시지의 오프셋을 `__consumer_offsets` 토픽에 커밋하는 작업**을 하나의 원자적 트랜잭션으로 묶음.
        
- **`transactional.id`**:
    
    - 재시작 시에도 유지되는 고유 ID로, 프로듀서를 식별하는 데 사용.
        
- **좀비 펜싱 (Zombie Fencing)**:
    
    - 브로커는 `transactional.id`와 함께 **에포크(epoch)** 번호를 관리함.
        
    - 새로운 프로듀서 인스턴스가 초기화되면 에포크가 증가하며, 브로커는 이전(낮은) 에포크를 가진 좀비 프로듀서의 요청을 거부하여 잘못된 쓰기를 원천 차단.
        
- **트랜잭션 코디네이터와 2단계 커밋**:
    
    - 모든 트랜잭션 과정은 **트랜잭션 코디네이터**에 의해 관리.
        
    - 코디네이터는 **2단계 커밋(Two-Phase Commit)** 프로토콜과 트랜잭션 로그(`_transaction_state` 토픽)를 사용하여 트랜잭션의 원자성을 보장.
        
        1. 진행 중인 트랜잭션의 존재와 관련 파티션을 로그에 기록함.
            
        2. 커밋/중단 의도를 로그에 기록함 (이 단계 이후에는 반드시 완료되어야 함).
            
        3. 모든 관련 파티션에 트랜잭션 마커(commit/abort)를 기록함.
            
        4. 트랜잭션 완료를 로그에 기록함.
            

#### **3.3. 관련 컴포넌트 구성**

- **프로듀서**: `transactional.id`를 반드시 설정해야 함.
    
- **컨슈머**:
    
    - 트랜잭션으로 쓰인 데이터를 올바르게 읽기 위해 `isolation.level` 설정을 **`read_committed`**로 지정.
        
    - 이 설정은 성공적으로 커밋된 트랜잭션의 메시지만 읽도록 보장하며, 진행 중이거나 중단된(aborted) 트랜잭션의 메시지는 반환하지 않음.
        
    - 오프셋 자동 커밋은 비활성화(`enable.auto.commit=false`)해야 함.
        

#### **3.4. 보장 범위 및 제한 사항**

- Kafka 트랜잭션의 보장 범위는 **Kafka 토픽에 대한 쓰기 작업에만 국한**.
    
- 다음과 같은 외부 시스템과의 상호작용은 트랜잭션 범위에 포함되지 않아 정확히 한 번을 보장할 수 없음:
    
    - 스트림 처리 중 이메일 발송, REST API 호출, 파일 시스템에 쓰기.
        
    - Kafka 토픽에서 데이터를 읽어 외부 데이터베이스에 쓰는 작업.
        
    - 이러한 문제는 **Outbox 패턴** 등을 사용하여 해결 가능.
        

#### **3.5. 구현 방법**

- **권장 방식**: Kafka Streams 애플리케이션에서 `processing.guarantee` 설정을 `exactly_once` 또는 `exactly_once_beta`로 지정하는 것이 가장 쉽고 안정적인 방법.
    
- **직접 API 사용**: 프로듀서와 컨슈머를 직접 제어하며 `initTransactions()`, `beginTransaction()`, `sendOffsetsToTransaction()`, `commitTransaction()`, `abortTransaction()` 등의 API를 순서에 맞게 호출하여 구현 가능.
    